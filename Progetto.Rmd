---
title: "Progetto HDDA AA2021/2022"
output: html_notebook
---


# Libraries

```{r message=FALSE, warning=FALSE, paged.print=FALSE}
if(!require(data.table)) install.packages("data.table")
if(!require(Hmisc)) install.packages("Hmisc")
if(!require(dplyr)) install.packages("dplyr")
if(!require(corrplot)) install.packages("corrplot")
if(!require(lubridate)) install.packages("lubridate")
if(!require(stringr)) install.packages("stringr")
if(!require(sampling)) install.packages("sampling")
if(!require(leaps)) install.packages("leaps")
if(!require(bestglm)) install.packages("bestglm")
if(!require(glmnet)) install.packages("glmnet")
if(!require(factoextra)) install.packages("factoextra")
if(!require(caret)) install.packages("caret")
if(!require(ranger)) install.packages("ranger")
if(!require(ordinalForest)) install.packages("ordinalForest")
if(!require(InformationValue)) install.packages("InformationValue")
if(!require(kernlab)) install.packages("kernlab")
if(!require(e1071)) install.packages("e1071")
if(!require(survival)) install.packages("survival")
if(!require(survminer)) install_github("kassambara/survminer", build_vignettes = FALSE)
library(data.table)
library(Hmisc)
library(dplyr)
library(corrplot)
library(lubridate)
library(stringr)
library(sampling)
library(leaps)
library(bestglm)
library(glmnet)
library(factoextra)
library(caret)
library(ranger)
library(ordinalForest) 
library(InformationValue) 
library(kernlab) 
library(e1071) 
library(survival) 
`%notin%` <- Negate(`%in%`)
```

# Data Ingestion

```{r message=FALSE, warning=FALSE, cache=TRUE, paged.print=FALSE}
acc_full <- fread("archive/accepted_2007_to_2018Q4.csv", sep = ",", header = T)
```

```{r, cache=TRUE}
variables <- c(
  "addr_state",
  "annual_inc",
  "application_type",
  "delinq_2yrs",
  "earliest_cr_line",
  "emp_length",
  #"emp_title", # troppi livelli, circa 600k
  "fico_range_high",
  "fico_range_low",
  "grade",
  "home_ownership",
  "initial_list_status",
  "int_rate",
  "issue_d",
  "last_pymnt_d",
  "loan_amnt",
  "funded_amnt",
  "loan_status",
  "mo_sin_old_il_acct",
  "mo_sin_old_rev_tl_op",
  "mort_acc",
  "num_bc_sats",
  "num_bc_tl",
  "num_op_rev_tl",
  "num_rev_accts",
  "num_rev_tl_bal_gt_0",
  "num_sats",
  "open_acc",
  "pct_tl_nvr_dlq",
  "percent_bc_gt_75",
  "pub_rec",
  "pub_rec_bankruptcies",
  "purpose",
  "revol_bal",
  "revol_util",
  "sub_grade",
  "tax_liens",
  "term",
  "total_acc",
  #"total_cu_tl",
  "verification_status"
)
```

```{r}
acc <- acc_full
acc <- acc[,..variables]
acc <- acc[complete.cases(acc),]
acc <- acc[!apply(acc, 1, function(x) any(x=="")),]
```

```{r}
fwrite(acc, "archive/accepted_clean.csv", sep = ",")
```

# Data Preparation
```{r}
acc <- fread("archive/accepted_clean.csv", sep=",",header=T)
acc <- as.data.frame(acc)
numeric_variables <- c(
  "annual_inc",
  "delinq_2yrs",
  "mo_sin_earliest_cr_line",
  "fico_range_high",
  "fico_range_low",
  "int_rate",
  "loan_amnt",
  "funded_amnt",
  "mo_sin_old_il_acct",
  "mo_sin_old_rev_tl_op",
  "mort_acc",
  "num_bc_sats",
  "num_bc_tl",
  "num_op_rev_tl",
  "num_rev_accts",
  "num_rev_tl_bal_gt_0",
  "num_sats",
  "open_acc",
  "pct_tl_nvr_dlq",
  "percent_bc_gt_75",
  "pub_rec",
  "pub_rec_bankruptcies",
  "revol_bal",
  "revol_util",
  "tax_liens",
  "total_acc"
)

acc <- acc %>%
  mutate(
    mo_sin_earliest_cr_line=as.integer(round((as.Date("2018-12-01")-lubridate::my(earliest_cr_line))/(365.25/12))),
    issue_d = lubridate::my(issue_d),
    last_pymnt_d = lubridate::my(last_pymnt_d),
    emp_length=as.numeric(str_extract(emp_length, "[0-9]+"))
  ) %>%
  mutate(
    emp_length = case_when(
      emp_length < 5 ~ "low",
      emp_length < 10 ~ "mid",
      T ~"high")) %>%
  select(-earliest_cr_line)

acc_with_current <- acc

acc <- acc %>% 
  filter(loan_status %notin% c("Current", "In Grace Period", "Late (16-30 days)")) %>%
  mutate(y=case_when(
    loan_status == "Late (31-120 days)" ~ 0,
    loan_status == "Charged Off" ~ 0,
    loan_status == "Default" ~ 0,
    loan_status == "Fully Paid" ~ 1
  )) %>%
  mutate(addr_state=case_when(
    addr_state %in% c("WA", "OR", "CA", "HI", "AL", "AK") ~ "West Coast",
    addr_state %in% c("MT", "ID", "NV", "UT", "CO", "WY") ~ "The Rocky Mountains",
    addr_state %in% c("AZ", "NM", "TX", "OK") ~ "South West",
    addr_state %in% c("ND", "SD", "NE", "KS", "MN", "IA", "MO", "WI", "IL", "IN", "MI", "OH") ~ "Midwest",
    addr_state %in% c("AR", "LA", "MS", "KY", "TN", "AL", "GA", "FL", "NC", "SC", "VA", "WV") ~ "South East",
    addr_state %in% c("ME", "VT", "NH", "MA", "RI", "CT") ~ "New England",
    addr_state %in% c("NY", "PA", "NJ", "MD", "DE", "DC") ~ "Mid Atlantic",
  )) %>%
  # livelli erano molto sbilanciati, optato per 3 livelli
  mutate(purpose=case_when(
    purpose %in% c("debt_consolidation") ~ "debt_consolidation",
    purpose %in% c("credit_card") ~ "credit_card",
    T ~ "other"
  )) %>% 
  mutate(
    addr_state=as.factor(addr_state),
    y=as.factor(y),
    application_type=as.factor(application_type),
    emp_length=as.factor(emp_length),
    grade=as.factor(grade),
    home_ownership=as.factor(home_ownership),
    initial_list_status=as.factor(initial_list_status),
    purpose=as.factor(purpose),
    sub_grade=as.factor(sub_grade),
    term=as.factor(term),
    verification_status=as.factor(verification_status),
  ) %>% select(-loan_status)
set.seed(1000)
source("data_preparation/outliers.R", print.eval = T)
```

Possiamo pensare di utilizzare anche i Current tipo con 90% gi√† ripagato. Ma ci servono? No!

# Data Exploration

### numero di osservazioni / tempo

```{r, fig.width=10, fig.height=6}
source("data_preparation/plot_osservazioni_e_tempo.R", print.eval = T)
```

### Pie chart default vs fully paid

```{r}
source("data_preparation/pie_chart_default_VS_fully_paid.R", print.eval = T)
piechart(acc,group="y") +
  scale_fill_manual(labels=c("Default", "Fully Paid"), values=c("darkred","darkgreen"))
```

### ROI boxplot/violinplot (for each grade?)

```{r}
source("data_preparation/ROI_violin.R", print.eval = T)
```


### Violin plot for each numeric variable and barplot for categorical variables

```{r, fig.width=10, fig.height=6}
source("data_preparation/all_violin.R", print.eval = T)
```


### Investigate correlations and fix


```{r}
corrplot(cor(acc[,numeric_variables]))
```

```{r}
cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}
# matrix of the p-value of the correlation
chart_pic_file = tempfile(pattern="file", tmpdir=tempdir(), fileext = ".png")
p.mat <- cor.mtest(acc[,numeric_variables])
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
png(filename = chart_pic_file, width = 900, height = 900, type = "cairo")
corrplot::corrplot(cor(acc[,numeric_variables]), method="color", col=col(200),  
         type="upper", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, tl.cex = .7, number.cex=0.75,  #Text label color and rotation
         # Combine with significance
         p.mat = p.mat, sig.level = 0.2, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=T 
         )
```

```{r pressure, out.width= '100%'}
knitr::include_graphics(chart_pic_file)
```


```{r}
ids <- sample(c(1:nrow(acc)), 8e4)
plot(acc[ids,"mo_sin_earliest_cr_line"], acc[ids,"mo_sin_old_rev_tl_op"])
```

```{r}
plot(acc[ids, "num_sats"], acc[ids, "open_acc"])
```

```{r}
### categorizzazione fico_mean (https://www.investopedia.com/terms/f/ficoscore.asp)
acc <- acc %>% 
  mutate(fico_mean = (fico_range_high+fico_range_low)/2) %>%
  select(-fico_range_high, -fico_range_low) %>% 
  mutate(fico_class=case_when(
    fico_mean <= 580 ~ "Poor",
    fico_mean > 580 & fico_mean <= 669 ~ "Fair",
    fico_mean > 670 & fico_mean <= 739 ~ "Good",
    fico_mean > 740 & fico_mean <= 799 ~ "Very Good",
    fico_mean > 800 ~ "Exceptional"
  )) %>% select(-fico_mean) %>% mutate(fico_class=as.factor(fico_class))

acc <- acc %>% 
  mutate(num_not_sats = open_acc - num_sats,
         num_bc_not_sats = num_bc_tl - num_bc_sats) %>%
  select(-num_sats, num_bc_sats)

# tolte le correlazioni, restano queste variabili esplicative numeriche
new_numeric_variables <- c(
  "annual_inc",
  "delinq_2yrs",
  "mo_sin_earliest_cr_line",
  "int_rate",
  "loan_amnt",
  "mo_sin_old_il_acct",
  "mo_sin_old_rev_tl_op",
  "mort_acc",
  "num_bc_not_sats",
  "num_bc_tl",
  "num_op_rev_tl",
  "num_rev_accts",
  "num_rev_tl_bal_gt_0",
  "num_not_sats",
  "open_acc",
  "pct_tl_nvr_dlq",
  "percent_bc_gt_75",
  "pub_rec",
  "pub_rec_bankruptcies",
  "revol_bal",
  "revol_util",
  "tax_liens",
  "total_acc"
)
corrplot(cor(acc[, new_numeric_variables]))
```


# Modeling

```{r}
model_variables = names(acc)[names(acc) %notin% c(
  "grade",
  "funded_amnt",
  "issue_d",
  "last_pymnt_d",
  "num_sats",
  "num_bc_sats",
  "sub_grade",
  "pub_rec_bankruptcies",
  "num_rev_accts",
  "mo_sin_old_rev_tl_op"
)]

model_acc <- acc[,model_variables] %>% relocate(y, .after = last_col())

model_acc[, new_numeric_variables[new_numeric_variables %in% model_variables]] = scale(model_acc[, new_numeric_variables[new_numeric_variables %in% model_variables]])

corrplot(cor(model_acc[, new_numeric_variables[new_numeric_variables %in% model_variables]]))
```


```{r}
set.seed(1000)
acc.balanced <- model_acc %>% group_by(y) %>% sample_n(min(summary(acc$y))) %>% ungroup()

train.balanced = sample_frac(acc.balanced, 0.8)
test.balanced = anti_join(acc.balanced,train.balanced)

```


```{r}
set.seed(1000)
fit.glm <- glm(y~., train.balanced, family="binomial")

yhat.glm <- predict(fit.glm, test.balanced)-1

confusionMatrix(test.balanced$y, yhat.glm)
```

```{r}
plotROC(test.balanced$y, yhat.glm)
```


```{r}
#PCA
set.seed(1000)
pca.res <- prcomp(scale(as.matrix(acc[,new_numeric_variables])))
fviz_eig(pca.res)

print(pca.res$sdev)

acc_pca <- as.data.frame(scale(as.matrix(acc[,new_numeric_variables])) %*% pca.res$rotation)[,1:8] # prime otto variabili
#acc_pca <- acc_pca %>% cbind(acc %>% select(-new_numeric_variables))
acc_pca <- acc_pca %>% cbind(acc%>%select(y))
```


```{r}
set.seed(1000)
acc.balanced.pca <- acc_pca %>% group_by(y) %>% sample_n(min(summary(acc_pca$y))) %>% ungroup()

train.balanced.pca <- sample_frac(acc.balanced.pca, 0.8)
test.balanced.pca <- anti_join(acc.balanced.pca,train.balanced.pca)

fit.pca <- glm(y~., train.balanced.pca, family="binomial")

yhat.pca <- predict(fit.pca, test.balanced.pca)

ytest.pca = test.balanced.pca$y

confusionMatrix(ytest.pca, yhat.pca)
```

```{r}
plotROC(ytest.pca, yhat.pca)
```


## Best Subset Selection (BSS)

```{r}
set.seed(1000)
fit.bss = step(fit.glm, direction = "backward", trace=T)

yhat.bss = predict(fit.bss, test.balanced %>% select(-y))

plotROC(test.balanced$y, yhat.bss)
```

## Ridge

```{r}
set.seed(1000)

Xlm.train <- model.matrix(fit.glm)[,-1]
fit.ridge <- glmnet(Xlm, train.balanced$y, alpha = 0, family="binomial", nlambda = 100)    # alpha=0: ridge

summary(fit.ridge)
```

```{r}
plot(fit.ridge, xvar="lambda")
```
```{r}
set.seed(1000)
K <- 10
fit.ridge.cv <- cv.glmnet(Xlm.train, train.balanced$y, alpha=0, nfolds = K, grouped = FALSE, family="binomial", type.measure = "auc")

plot(fit.ridge.cv)
```

```{r}
Xlm.test = model.matrix(glm(y ~ ., test.balanced, family = "binomial"))[,-1]

yhat.ridge.cv.1se = predict(fit.ridge.cv$glmnet.fit, Xlm.test, s = "lambda.1se") manually

confusionMatrix(test.balanced$y, yhat.ridge.cv.1se)
```
```{r}
plotROC(test.balanced$y, yhat.ridge.cv.1se)
```


## Lasso
```{r}
set.seed(1000)
K <- 10
fit.lasso.cv <- cv.glmnet(Xlm, train.balanced$y, alpha=1, nfolds = K, grouped = FALSE, family="binomial", type.measure="auc" ,parallel=TRUE)
plot(fit.lasso.cv)
coef(fit.lasso.cv)
```

```{r}
set.seed(1000)
yhat.lasso.cv.1se <- predict(fit.lasso.cv, Xlm.test, s = "lambda.1se")
confusionMatrix(
  test.balanced$y,
  yhat.lasso,
  threshold = InformationValue::optimalCutoff(test.balanced$y, yhat.lasso, optimiseFor = "misclasserror"))
plotROC(test.balanced$y, yhat.lasso.cv.1se)
```



## Caret

```{r}
set.seed(1000)

fit.svm = train(
  y ~ .,
  data=train.balanced,
  method="svmLinear2",
  trControl=trainControl(method="repeatedcv", number=10, repeats=20),
  tuneGrid=expand.grid(cost=3^(-7:7))
)

```


# Survival Analysis

In order to perform survival analysis we define three possible outcomes for a lending: "Fully Paid", "Default" and "Pre-Paid", whose meanings are pretty clear.

To distinguish between Regalur Payment and Early Payment we define a tolerance of -1 month since our dates are all represented as month-year.

```{r}
acc_surv <- acc
acc_surv <- acc_surv %>% 
  mutate(term=as.numeric(substring(as.character(term),0,2))) %>%
  mutate(actual_duration_to_term = as.numeric(last_pymnt_d - issue_d) / (term*30)) %>%
  mutate(actual_duration_to_term = as.numeric(last_pymnt_d - issue_d) / (term*30))
hist(as.numeric(acc_surv[acc$y==1, "actual_duration_to_term"]), col = "blue")
hist(as.numeric(acc_surv[acc$y==0, "actual_duration_to_term"]), col="red",add =T)
acc_surv <- acc_surv %>%
  mutate(y = as.factor(case_when(
      y == 0 ~ 0, ### Deafult
      (y == 1) & (actual_duration_to_term < 0.8) ~ 2, ### Early Payment
      T ~ 1 ### Regular Payment
    ))
  )
piechart(acc_surv, "y")
```

```{r}
fit <- survfit(Surv(actual_duration_to_term, y) ~ 1, data = acc_surv)
plot(fit, col=c("black", "red"), ylab="Survival", xlab="time")
summary(fit, times = 10)
```


# Tuning



# Conclusions