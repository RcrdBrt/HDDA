---
title: "Progetto HDDA AA2021/2022"
output: html_notebook
---

# Introduzione

Il *Social Lending* è una forma di prestito erogato da privati per privati via Internet che nasce in Gran Bretagna nel 2005 e si afferma definitivamente nel mercato finanziario a seguito della crisi del 2008. Uno dei principali intermediari al mondo di Social Lending è la piattaforma *LendingClub*, che a partire dalla fondazione nel 2006 in soli 9 anni ha gestito 16 miliardi di dollari. \
Con il presente lavoro si applicano i metodi di Statistical Learning ai dati messi a disposizione dalla piattaforma, con l'obiettivo di allenare modelli in grado di riconoscere i prestiti *"buoni"*, ovvero che saranno ripagati, da quelli *"cattivi"*. Tali modelli potranno così essere utilizzati nella definizione di strategie di investimento personalizzate, che tengano conto in maniera trasparente della propensione al rischio dell'investitore.

I modelli che verranno testati sono: 
- Regressione Logistica 
  + base
  + con PCA
  + con Backward Elimination
  + con penalizzazione Ridge
  + con penalizzazione Lasso 
- Random Forest 
- Modello di Cox 

La metrica che sarà utilizzata per valutare i modelli è la Precision\@K, una misura della precisione del modello avendo selezionato il numero di suggerimenti richiesti.

```{r message=FALSE, warning=FALSE, paged.print=FALSE, include=F}
if(!require(data.table)) install.packages("data.table")
if(!require(tibble)) install.packages("tibble")
if(!require(Hmisc)) install.packages("Hmisc")
if(!require(dplyr)) install.packages("dplyr")
if(!require(ggplot2)) install.packages("ggplot2")
if(!require(scales)) install.packages("scales")
if(!require(tidyr)) install.packages("tidyr")
if(!require(corrplot)) install.packages("corrplot")
if(!require(lubridate)) install.packages("lubridate")
if(!require(stringr)) install.packages("stringr")
if(!require(sampling)) install.packages("sampling")
if(!require(leaps)) install.packages("leaps")
if(!require(bestglm)) install.packages("bestglm")
if(!require(glmnet)) install.packages("glmnet")
if(!require(factoextra)) install.packages("factoextra")
if(!require(caret)) install.packages("caret")
if(!require(ranger)) install.packages("ranger")
if(!require(randomForest)) install.packages("randomForest")
if(!require(InformationValue)) install.packages("InformationValue")
if(!require(kernlab)) install.packages("kernlab")
if(!require(e1071)) install.packages("e1071")
if(!require(survival)) install.packages("survival")
if(!require(survminer)) install_github("kassambara/survminer", build_vignettes = FALSE)
if(!require(riskRegression)) install.packages("riskRegression")
if(!require(parallel)) install.packages("doParallel")
if(!require(doMC)) install.packages("doMC")
if(!require(patchwork)) install.packages("patchwork")

library(data.table)
library(tibble)
library(Hmisc)
library(tidyr)
library(dplyr)
library(ggplot2)
library(corrplot)
library(lubridate)
library(stringr)
library(sampling)
library(leaps)
library(bestglm)
library(glmnet)
library(factoextra)
library(caret)
library(ranger)
library(randomForest) 
library(InformationValue) 
library(kernlab) 
library(e1071) 
library(survival)
library(riskRegression)
library(parallel)
library(doMC)
library(pander)
library(patchwork)
library(car)

`%notin%` <- Negate(`%in%`)

registerDoMC(cores = detectCores())
#cl = makePSOCKcluster(detectCores())
#registerDoParallel(cl)

piechart <- function(d, group, legend_title = "Outcome"){
  piepercent <- d %>% 
    group_by((!!sym(group))) %>% 
    summarise(n_group = n()) %>% 
    mutate(n_perc= round( n_group/nrow(d)* 100,2))
  
  ggplot(piepercent, aes(x = "", y = n_perc, fill = !!sym(group))) +
    geom_bar(width = 1, stat = "identity", color = "white") +
    coord_polar("y", start = 0) +
    geom_text(aes(label = n_perc), position = position_stack(vjust = 0.5),color = "white")+
    guides(fill=guide_legend(title=legend_title))+
    theme_void()
}

cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}

MyCorrelationMatrix <- function(d){
# matrix of the p-value of the correlation
  chart_pic_file <- tempfile(pattern="file", tmpdir=tempdir(), fileext = ".png")
  p.mat <- cor.mtest(d)
  col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
  png(filename = chart_pic_file, width = 900, height = 900, type = "cairo")
  corrplot::corrplot(cor(d), method="color", col=col(200),  
           type="upper", 
           addCoef.col = "black", # Add coefficient of correlation
           tl.col="black", tl.srt=45, tl.cex = .7, number.cex=0.75,  #Text label color and rotation
           # Combine with significance
           p.mat = p.mat, sig.level = 0.2, insig = "blank", 
           # hide correlation coefficient on the principal diagonal
           diag=T 
           )
  chart_pic_file
}

MyConfusionMatrix <- function(actuals, predictions, threshold=0.5, title=""){
  cm <- caret::confusionMatrix(as.factor(ifelse(predictions>threshold,1,0)), actuals, threshold, dnn=c("Prediction", "Actual"), positive="1", mode="prec_recall")
  ggplot(as.data.frame(cm$table), aes(Actual, Prediction, fill= Freq)) +
    geom_tile() + geom_text(aes(label=Freq), fontface="bold") +
    scale_fill_distiller(palette="Greens",guide="none", direction = 1) +
    labs(x = "Actual",y = "Prediction", title=title, subtitle=
           paste(
             "Precision at 0.5 threshold:",
             round(precision(actuals,predictions,threshold),3)*100, "%")) +
    scale_x_discrete(labels=c("Default", "Fully Paid")) +
    scale_y_discrete(labels=c("Fully Paid","Default"), limits=rev) +
    theme_minimal() + 
    theme(plot.title = element_text(hjust = 0.5, size = 16),
          plot.subtitle = element_text(hjust = 0.5, size = 12)) 
}


plot_precision_vs_npred <- function(actuals, predictions, title=""){ ### non serve più, cancellare T.T
  p <- vector("list", length(predictions))
  names(p) <- names(predictions)
  n <- vector("list", length(predictions))
  names(n) <- names(predictions)
  for (i in 1:length(predictions)){
      for (threshold in seq(0,1,0.01)){
        p[[i]] <- c(p[[i]],precision(actuals, predictions[[i]], threshold = threshold))
        n[[i]] <- c(n[[i]],length(predictions[[i]][predictions[[i]] >= threshold]))
      }
  }
  
  res <- as.data.frame(list(p=p,n=n))
  res$i <- 1:nrow(res)
  res <- gather(res,var,val,-i) %>% separate(var, c("variable", "Model")) %>% reshape(idvar = c("i","Model"), timevar = "variable", direction = "wide")
  names(res)[c(3,4)] <- c("p","n")
  
  res <- res %>% arrange(Model, p)
  plotly::plot_ly(res) %>%
  plotly::add_trace(x=~p*100, y = ~n/length(actuals)*100, yaxis="y", type="scatter", mode = "lines+markers", color=~Model, opacity = 1) %>% 
  plotly::add_trace(x=~p*100, y = ~round(n/length(actuals)*4e4), yaxis="y2", type="scatter", mode = "lines+markers", color=~Model, opacity = 0, showlegend=F) %>%     
  plotly::layout(title = "Results",
                 xaxis = list(title = 'Precision',  ticksuffix = "%"),
                 yaxis = list(title = 'Percentage of predicted Fully Paid', ticksuffix = "%", gridcolor=rgb(0, 0, 0, max = 255, alpha = 80)),
                 yaxis2= list(tickfont = list(color = "red"), gridcolor=rgb(255, 0, 0, max = 255, alpha = 20), overlaying = "y",side = "right", automargin = T,title = "Number of predicted Fully Paid"),
                 legend = list(x=0.7,y=0.9))

}

precision_at_k <- function(actuals, predictions){
  d <- data.frame(actuals = actuals, score = predictions) %>%
    arrange(-score)
  d$k <- 1:nrow(d)
  p_at_k <- rep(0,nrow(d))
  n_relevant <- 0
  for (k in 1:nrow(d)){
    if (d[k,"actuals"] == 1){
      n_relevant <- n_relevant+1
    }
    p_at_k[k] <- n_relevant/k
  }
  p_at_k
}

plot_precision_at_k <- function(actuals, predictions, resolution_k=100){
  test_size <- length(actuals)
  p_at_k <- vector("list", length(predictions))
  names(p_at_k) <- names(predictions)
  for (i in 1:length(predictions)){
    p_at_k[[i]] <- precision_at_k(actuals, predictions[[i]])
  }
  p_at_k <-  p_at_k %>% 
    sapply('[', seq(max(sapply(p_at_k, length)))) %>% 
    as.data.frame()
  p_at_k <- p_at_k %>%
    mutate(k=1:nrow(p_at_k)) %>%
    gather(Model, p,-k) %>%
    filter( k == 1 | k %% resolution_k == 0)
  plotly::plot_ly(p_at_k) %>%
  plotly::add_trace(x=~round(k/test_size*100,3), y = ~p*100, type="scatter", mode = "lines+markers", color=~Model) %>% 
  plotly::add_trace(x=~round(k/test_size*4e4), y = ~p*100, xaxis="x2", type="scatter", mode = "lines+markers", color=~Model, opacity = 0, showlegend=F) %>%     
  plotly::layout(xaxis = list(title = 'K', ticksuffix= "%", gridcolor=rgb(0, 0, 0, max = 255, alpha = 60)),
                 xaxis2= list(tickfont = list(color = "red"), gridcolor=rgb(255, 0, 0, max = 255, alpha = 20), overlaying = "x",side = "top", automargin = T, title = list(text="Expected K")),
                 yaxis = list(title = 'Precision @ K', ticksuffix = "%", gridcolor=rgb(0, 0, 0, max = 255, alpha = 60)),
                 legend = list(x=0.8,y=0.9))
} 
```


# Data Ingestion

Il dataset utilizzato proviene da [kaggle](https://www.kaggle.com/wordsforthewise/lending-club). \
Le osservazioni del dataset rappresentano i prestiti richiesti tramite la piattaforma nel periodo 2007-2018, di questi vengono selezionati solo i prestiti che sono stati erogati (contenuti nel file: accepted_2007_to_2018Q4.csv) e si ottengono così 2,260,701 osservazioni. \
Il numero di attributi ammonta a 151, essi descrivono le caratteristiche del prestito, tra cui: la formulazione della richiesta, la situazione finanziaria del richiedente, l'esito del prestito, ecc.

```{r message=FALSE, warning=FALSE, cache=TRUE, paged.print=FALSE}
acc_full <- fread("archive/accepted_2007_to_2018Q4.csv", sep = ",", header = T)
```

Non tutti i 151 attributi sono utilizzabili poichè vengono aggiornati periodicamente dalla piattaforma, pertanto alcuni di essi tengono conto dell'evoluzione del prestito, informazione che ovviamente non può essere utilizzata per la costruzione di modelli di classificazione. Dopo aver studiato ciascuno dei 151 attributi ne sono stati infine selezionati 40.

Attributo|Tipo|Significato
-|-|-
addr_state|Factor|Stato di provenienza del richiedente (USA)
annual_inc|Int|Reddito annuale fornito dal richiedente
application_type|Factor|Tipo di richiesta: individuale o congiunta
delinq_2yrs|Int|Numero di insolvenze rateali superiori a 30 giorni segnalate negli ultimi 2 anni nel registro di credito del richiedente
dti|Float|Rapporto tra debiti e reddito del richiedente
earliest_cr_line|Date|Data in cui il richiedente ha aperto la sua prima linea di credito
emp_length|Int|Durata dell'impiego in anni. Il valore varia tra 0 e 10, dove 10 indica 10 o più anni
fico_range_high|Factor|Estremo superiore dell'intervallo FICO del richiedente
fico_range_low|Factor|Estremo inferiore dell'intervallo FICO del richiedente
grade|Factor|Score assegnato da parte di LendingClub al richiedente
home_ownership|Factor|Indica se il richiedente è proprietario di un immobile o è in affitto
initial_list_status|Factor|Copertura del prestito da parte di un singolo investitore o meno
int_rate|Float|Tasso annuale del prestito
issue_d|Date|Data di emissione dei fondi (mese-anno)
last_pymnt_d|Date|Data dell'ultimo pagamento (mese-anno)
loan_amnt|Int|Importo richiesto
funded_amnt|Int|Importo erogato
**loan_status**|Factor|Stato del prestito (in corso, default, in ritardo, ...), variabile target.
mo_sin_old_il_acct|Int|Mesi trascorsi dalla più vecchia linea di credito bancaria
mo_sin_old_rev_tl_op|Int|Mesi trascorsi dall'apertura del più vecchio conto revolving
mort_acc|Int|Numero di mutui intestati al richiedente
num_bc_sats|Int|Numero di solvenze degli estratti conto delle carte di credito del cliente
num_bc_tl|Int|Numero delle carte del cliente
num_op_rev_tl|Int|Numero di carte revolving del cliente
num_rev_accts|Int|Numero di conti revolving
num_rev_tl_bal_gt_0|Int|Numero di transazioni revolving con saldo maggiore di 0
num_sats|Int|Numero di linee di credito solventi intestate al richiedente
open_acc|Int|Numero di linee di credito aperte
pct_tl_nvr_dlq|Int|Percentuale di rinnovi di credito solventi
percent_bc_gt_75|Int|Percentuale di carte di credito sopra al massimale di oltre il 75%
pub_rec|Int|Numero di ritardi di pagamento
pub_rec_bankruptcies|Factor|Numero di volte in cui il cliente ha dichiarato bancarotta
purpose|Factor|Motivo del prestito, espresso dal richiedente
revol_bal|Int|Saldo totale del credito revolving del richiedente
revol_util|Float|Percentuale di utilizzo del credito revolving da parte del richiedente
sub_grade|Factor|Score assegnato da parte di LendingClub al richiedente
tax_liens|Int|Numero di ipoteche intestate al richiedente
term|Int|Numero di rate, durata del prestito
total_acc|Int|Numero di prestiti in corso al momento della richiesta
verification_status|Factor|Verifica delle informazioni fornite dal richiedente

```{r cache=TRUE, include=F}
variables <- c(
  "addr_state",
  "annual_inc",
  "dti",
  "application_type",
  "delinq_2yrs",
  "earliest_cr_line",
  "emp_length",
  "fico_range_high",
  "fico_range_low",
  "grade",
  "home_ownership",
  "initial_list_status",
  "int_rate",
  "issue_d",
  "last_pymnt_d",
  "loan_amnt",
  "funded_amnt",
  "loan_status",
  "mo_sin_old_il_acct",
  "mo_sin_old_rev_tl_op",
  "mort_acc",
  "num_bc_sats",
  "num_bc_tl",
  "num_op_rev_tl",
  "num_rev_accts",
  "num_rev_tl_bal_gt_0",
  "num_sats",
  "open_acc",
  "pct_tl_nvr_dlq",
  "percent_bc_gt_75",
  "pub_rec",
  "pub_rec_bankruptcies",
  "purpose",
  "revol_bal",
  "revol_util",
  "sub_grade",
  "tax_liens",
  "term",
  "total_acc",
  "verification_status"
)
```

```{r message=FALSE, warning=FALSE}
acc <- acc_full
acc <- acc[,..variables]
acc <- acc[complete.cases(acc),]
acc <- acc[!apply(acc, 1, function(x) any(x=="")),]
fwrite(acc, "archive/accepted_clean.csv", sep = ",")
```

# Data Exploration e Preparation

Conservati gli attributi utili allo scopo ed eliminate le osservazioni con valori mancanti, si procede alla fase di esplorazione e pulizia del dataset. Per gli attributi numerici è stato scelto di eliminare gli outliers oltre la soglia di $3\sigma$ dalla media, mentre per gli attributi categorici è stata eseguita un'analisi individuale, analizzandone la numerosità dei livelli e riducendola ove fosse eccessiva. \
In particolare l'attributo sullo stato di provenienza del richiedente (*addr_state*), è stato portato da 52 livelli a 7, rappresentanti le macro-aree geografiche degli Stati Uniti (West Coast, MidWest, ...). L'attributo *purpose* è stato portato da 15 livelli a 3, mantenendo i 2 più numerosi e accorpando tutti gli altri in *other*, eliminando così livelli presenti in poche migliaia di osservazioni.
L'attributo *home_ownership* contiene dei livelli con poche centinaia di osservazioni, pertanto queste vengono rimosse.
L'attributo *emp_length*, inizialmente numerico, è stato convertito in un fattore a tre livelli: low, mid, high.
Infine l'attributo *loan_status* viene trasformato in un fattore a 2 livelli: 0 se il prestito è in stato di default o in forte ritardo, 1 se è stato rimborsato con successo.
successo. I presetiti ancora in corso e non in forte ritardo sono invece stati rimossi.

Gli attributi di tipo Date sono stati convertiti in attrbuti numerici espressi come "numero di mesi da tale data fino a dicembre 2018", per conformità ad altri attributi numerici già espressi in tale modo.

```{r message=FALSE, warning=FALSE}
acc <- fread("archive/accepted_clean.csv", sep=",",header=T)
acc <- as.data.frame(acc)
numeric_variables <- c(
  "annual_inc",
  "dti",
  "delinq_2yrs",
  "mo_sin_earliest_cr_line",
  "fico_range_high",
  "fico_range_low",
  "int_rate",
  "loan_amnt",
  "funded_amnt",
  "mo_sin_old_il_acct",
  "mo_sin_old_rev_tl_op",
  "mort_acc",
  "num_bc_sats",
  "num_bc_tl",
  "num_op_rev_tl",
  "num_rev_accts",
  "num_rev_tl_bal_gt_0",
  "num_sats",
  "open_acc",
  "pct_tl_nvr_dlq",
  "percent_bc_gt_75",
  "pub_rec",
  "pub_rec_bankruptcies",
  "revol_bal",
  "revol_util",
  "tax_liens",
  "total_acc"
)

acc <- acc %>%
  mutate(
    mo_sin_earliest_cr_line=as.integer(round((as.Date("2018-12-01")-lubridate::my(earliest_cr_line))/(365.25/12))),
    issue_d = lubridate::my(issue_d),
    last_pymnt_d = lubridate::my(last_pymnt_d),
    emp_length=as.numeric(str_extract(emp_length, "[0-9]+"))
  ) %>%
  mutate(
    emp_length = case_when(
      emp_length < 5 ~ "low",
      emp_length < 10 ~ "mid",
      T ~"high")) %>%
  select(-earliest_cr_line)

acc_with_current <- acc

acc <- acc %>% 
  filter(loan_status %notin% c("Current", "In Grace Period", "Late (16-30 days)")) %>%
  mutate(y=case_when(
    loan_status == "Late (31-120 days)" ~ 0,
    loan_status == "Charged Off" ~ 0,
    loan_status == "Default" ~ 0,
    loan_status == "Fully Paid" ~ 1
  )) %>% 
  mutate(addr_state=case_when(
    addr_state %in% c("WA", "OR", "CA", "HI", "AL", "AK") ~ "West Coast",
    addr_state %in% c("MT", "ID", "NV", "UT", "CO", "WY") ~ "The Rocky Mountains",
    addr_state %in% c("AZ", "NM", "TX", "OK") ~ "South West",
    addr_state %in% c("ND", "SD", "NE", "KS", "MN", "IA", "MO", "WI", "IL", "IN", "MI", "OH") ~ "Midwest",
    addr_state %in% c("AR", "LA", "MS", "KY", "TN", "AL", "GA", "FL", "NC", "SC", "VA", "WV") ~ "South East",
    addr_state %in% c("ME", "VT", "NH", "MA", "RI", "CT") ~ "New England",
    addr_state %in% c("NY", "PA", "NJ", "MD", "DE", "DC") ~ "Mid Atlantic",
  )) %>%
  # livelli erano molto sbilanciati, optato per 3 livelli
  mutate(purpose=case_when(
    purpose %in% c("debt_consolidation") ~ "debt_consolidation",
    purpose %in% c("credit_card") ~ "credit_card",
    T ~ "other"
  )) %>% 
  mutate(
    addr_state=as.factor(addr_state),
    y=as.factor(y),
    application_type=as.factor(application_type),
    emp_length=as.factor(emp_length),
    grade=as.factor(grade),
    home_ownership=as.factor(home_ownership),
    initial_list_status=as.factor(initial_list_status),
    purpose=as.factor(purpose),
    sub_grade=as.factor(sub_grade),
    term=as.factor(term),
    verification_status=as.factor(verification_status)
  ) %>% 
  filter(home_ownership %notin% c("ANY", "NONE", "OTHER"))  %>%
  mutate(home_ownership = as.factor(as.character(home_ownership))) %>% # remove empty levels
  select(-loan_status)
set.seed(1000)
source("data_preparation/outliers.R", print.eval = T)
```

A seguito di questa prima pulizia vengono presentate alcune visualizzazioni utili alla comprensione del contesto.

## Numero di osservazioni / tempo

```{r fig.height=6, fig.width=10, message=FALSE, warning=FALSE}
month_summary_with_current <- 
  acc_with_current %>% 
  group_by(issue_d) %>% 
  summarise(n_current= n())

month_summary <- 
  acc %>% 
  group_by(issue_d) %>% 
  summarise(n = n())

month_summary_full <- 
  acc_full %>% 
  mutate(issue_d = lubridate::my(issue_d)) %>%
  group_by(issue_d) %>% 
  summarise(n_full= n()) %>%
  left_join(month_summary_with_current) %>%
  left_join(month_summary) 

plotly::plot_ly(month_summary_full, x = ~issue_d) %>% 
  plotly::add_trace(y = ~n_full, mode = "lines+markers", name = "All", opacity = 0.2) %>%
  plotly::add_trace(y = ~n_current, mode = "lines+markers", name = "Senza Missing Values", opacity = 0.5) %>%
  plotly::add_trace(y = ~n, mode = "lines+markers", name = "Senza Missing Values e Current", opacity = 1) %>%
  plotly::layout(title = "Crescita di LendingClub",  xaxis = list(title = 'Data'),
                 yaxis = list(title = 'Numero prestiti finanziati'),
                 legend = list(x=0.1,y=0.9))
```


```{r include=F}
rm(acc_full)
rm(acc_with_current)
```

Si osserva la forte espansione della piattaforma che a partire dal 2012 assume un carattere lineare, per arrivare negli anni più recenti a oltre 40,000 prestiti erogati al mese.
Si nota come prima di agosto 2012 non siano presenti osservazioni senza valori mancanti, inoltre si nota come molti dei prestiti più recenti siano ancora in corso, poichè ciò non ci consente di conoscere il loro esito, tali prestiti sono esclusi dall'analisi.

#Il lettore potrà notare una certa "mano facile" nell'eliminazione delle osservazioni... dirlo? secondo me sì, cioè dobbiamo far capire che siamo consapevoli di quello che facciamo#


## Distribuzione Loan Status

```{r}
piechart(acc,group="y") +
  scale_fill_manual(labels=c("Default", "Fully Paid"), values=c("darkred","darkgreen"))
```

Si osserva come il dataset sia fortemente sbilanciato, infatti il 79% dei prestiti erogati viene ripagato. Questo aspetto dovrà essere tenuto di conto in fase di costruzione dei modelli.

## Altre Distribuzioni

```{r fig.height=6, fig.width=10, message=FALSE, warning=FALSE}
source("data_preparation/all_violin.R", print.eval = T)
```

Osservando le distribuzioni degli attributi numerici si nota come la rimozione degli outliers abbia avuto successo, tuttavia sono presenti distribuzioni fortemente asimmetriche. Anche alcuni attributi categorici presentano sbilanciamento dei livelli.

## Analisi della correlazione

L'ultimo quesito dell'analisi esplorativa è l'eventuale presenza di correlazione tra gli attributi.

```{r , out.width= '100%'}
cor1 <- MyCorrelationMatrix(acc[,numeric_variables])
knitr::include_graphics(cor1)
```

Dalla matrice di correlazione si osserva la presenza di un elevato numero di attributi tra loro correlati, in particolare quelli relativi alla situazione finanziaria del richiedente (conti, carte, linee di credito, ...). Poichè la presenza di tale correlazione ci condurrebbe a significatività fittizie occorre eliminarla.
Gli attributi *fico_range_low* e *fico_range_high* hanno distanza costante su tutte le osservazioni, se ne estrae quindi la media e si procede infine a riassumerli in 5 livelli come di consuetudine ([link](https://www.investopedia.com/terms/f/ficoscore.asp)).
Le coppie di attributi (*num_sats*, *open_acc*) e (*num_bc_sats*, *num_bc_tl*) hanno forte scorrelazione, si decide pertanto di considerare il numero di conti/carte non soddisfacenti piuttosto che quelli soddisfacenti.

```{r}
### categorizzazione fico_mean (https://www.investopedia.com/terms/f/ficoscore.asp)
acc <- acc %>% 
  mutate(fico_mean = (fico_range_high+fico_range_low)/2) %>%
  select(-fico_range_high, -fico_range_low) %>% 
  mutate(fico_class=case_when(
    fico_mean <= 580 ~ "Poor",
    fico_mean > 580 & fico_mean <= 669 ~ "Fair",
    fico_mean > 670 & fico_mean <= 739 ~ "Good",
    fico_mean > 740 & fico_mean <= 799 ~ "Very Good",
    fico_mean > 800 ~ "Exceptional"
  )) %>% select(-fico_mean) %>% mutate(fico_class=as.factor(fico_class))

acc <- acc %>% 
  mutate(num_not_sats = (open_acc - num_sats)/open_acc,
         num_bc_not_sats = (num_bc_tl - num_bc_sats)/num_bc_tl) %>%
  select(-num_sats, num_bc_sats)

# tolte le correlazioni, restano queste variabili esplicative numeriche
new_numeric_variables <- c(
  "annual_inc",
  "dti",
  "delinq_2yrs",
  "mo_sin_earliest_cr_line",
  "int_rate",
  "loan_amnt",
  "mo_sin_old_il_acct",
  "mo_sin_old_rev_tl_op",
  "mort_acc",
  "num_bc_not_sats",
  "num_bc_tl",
  "num_op_rev_tl",
  "num_rev_accts",
  "num_rev_tl_bal_gt_0",
  "num_not_sats",
  "open_acc",
  "pct_tl_nvr_dlq",
  "percent_bc_gt_75",
  "pub_rec",
  "pub_rec_bankruptcies",
  "revol_bal",
  "revol_util",
  "tax_liens",
  "total_acc"
)
cor2 <- MyCorrelationMatrix(acc[,new_numeric_variables])
knitr::include_graphics(cor2)
```

Permangono ancora alcuni attributi correlati che vengono quindi rimossi: *pub_rec_bankruptcies*, *num_rev_accts*, *mo_sin_old_rev_tl_op*. Si rimuovono inoltre *grade* e *sub_grade* essendo degli score attribuiti dalla piattaforma potenzialmente aggiornati a seguito dell'evoluzione del prestito.

```{r}
model_variables <-  names(acc)[names(acc) %notin% c(
  "grade",
  "funded_amnt", # non nota al momento dell'utilizzo dei modelli
  "issue_d",
  "last_pymnt_d",
  "num_sats",
  "num_bc_sats",
  "sub_grade",
  "pub_rec_bankruptcies",
  "num_rev_accts",
  "mo_sin_old_rev_tl_op"
)]

model_num_variables <- model_variables[model_variables %in% new_numeric_variables]

model_acc <- acc[,model_variables] %>% relocate(y, .after = last_col())
```

# Modeling

Si procede alla costruzione di training set e test set, con metodo hold-out e rapporto 70-30. Inoltre si normalizzano le variabili numeriche.

```{r message=F}
set.seed(1000)
train <- sample_frac(model_acc, 0.7)
test <- anti_join(model_acc,train)

scaling <- preProcess(train, method = c("center", "scale"))
train <- predict(scaling,train)
test <- predict(scaling, test)

train.under <- train %>% group_by(y) %>% slice_sample(n=min(table(train$y))) %>% ungroup()
```

Per trattare lo sbilanciamento della variabile target si costruiscono dei pesi a seconda del numero di osservazioni.

```{r}
model_weights <- ifelse(train$y == "0",
                        (1/table(train$y)[1]) * 0.5, ### (1 / numero osservazioni classe 0) / 2
                        (1/table(train$y)[2]) * 0.5) ### (1 / numero osservazioni classe 1) / 2
```

## Logistic Regression

### Base

```{r}
fit.glm.unbalanced <- glm(y~., train, family="binomial")
yhat.glm.unbalanced <- predict(fit.glm.unbalanced, test, type="response")
cat("Accuracy of Unbalanced Model:", 1-misClassError(test$y, yhat.glm.unbalanced))
```

```{r}
set.seed(1000)
fit.glm.under <- glm(y~., train.under, family="binomial")
yhat.glm.under<- predict(fit.glm.under, test, type="response")
cat("Accuracy of UnderSampling Model:", 1-misClassError(test$y, yhat.glm.under))
```

```{r}
fit.glm.weighted <- glm(y~., train, family="binomial", weights=model_weights)
yhat.glm.weighted <- predict(fit.glm.weighted, test, type="response")
cat("Accuracy of Balanced Model:", 1-misClassError(test$y, yhat.glm.weighted))
```

```{r fig.width=10, fig.height=4}
p1 <- MyConfusionMatrix(test$y, yhat.glm.unbalanced, title="Logit Unbalanced")
p2 <- MyConfusionMatrix(test$y, yhat.glm.under, title="Logit UnderSampling")
p3 <- MyConfusionMatrix(test$y, yhat.glm.weighted, title="Logit Weighted")

p1+p2+p3
```

```{r}
plot_precision_at_k(test$y, list("Logit Unbalanced"=yhat.glm.unbalanced, "Logit Undersampling"=yhat.glm.under, "Logit Weighted"=yhat.glm.weighted))
```

Il bilanciamento può essere eseguito tramite due approcci: l'utilizzo dei pesi o l'undersampling, ciò ci permetterà di avere previsioni più attendibili sulla classe minoritaria (*Default*), al costo tuttavia di peggiorare l'accuracy totale del nostro modello. Nonostante il guadagno sia minimo, come si nota nell'ultimo grafico osservando la distanza tra la curva verde e le altre due, esso è presente e ci guida così verso la scelta di un train set bilanciato. Il bilanciamento viene infine eseguito con tecnica di undersampling poichè porta un risultato perfettamente comparabile con l'utilizzo dei pesi ma a un costo computazionale nettamente inferiore.

```{r}
InformationValue::plotROC(test$y, yhat.glm.under)
```

Il modello di Regressione Logistica con undersampling ha un valore di AUC pari a 70.4%, questo è il punto partenza, infatti con tale valore confronteremo i modelli successivi per avere un'indicazione di quale sia il migliore.

```{r}
train <- train.under
```

### PCA

```{r}
pca.res <- prcomp(train[, model_num_variables])

p1 <- ggplot()+
  geom_point(aes(x=1:length(pca.res$sdev), y=pca.res$sdev, col=pca.res$sdev<1)) +
  geom_line(aes(x=1:length(pca.res$sdev),y=1), color="red") + 
  geom_text(aes(x=1:length(pca.res$sdev), y=pca.res$sdev+0.1, label=1:length(pca.res$sdev))) +
  scale_color_manual(values = c("red", "blue"), guide="none") +
  labs(x="Component", y="Standard Deviation", title = "PCA components") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 16))

p2 <- fviz_eig(pca.res, chioce="eigenvalue", ggtheme = theme_minimal() + theme(plot.title = element_text(hjust = 0.5, size = 16)))
p1+p2
```

Utilizziamo la tecnica della PCA per ridurre il numero di predittori e al contempo eliminare l'eventuale multi-collinearità residua. Vengono selezionati le componenti principali con deviazione standard maggiore di 1.0, poichè esse racchiudono più informazione delle variabili di partenza. Le sette componenti così selezionate spiegano il ~66% della varianza totale.

```{r}
train.pca <- as.data.frame(as.matrix(train[,model_num_variables]) %*% pca.res$rotation)[,1:7] # prime sette variabili
test.pca <- as.data.frame(as.matrix(test[,model_num_variables]) %*% pca.res$rotation)[,1:7] # prime sette variabili

train.pca$y <- train$y
test.pca$y <- test$y
```

```{r}
fit.pca <- glm(y~., train.pca, family="binomial")

yhat.pca <- predict(fit.pca, test.pca, type="response")

MyConfusionMatrix(test.pca$y, yhat.pca, title = "Logit - PCA")

cat("Accuracy = ", 1-misClassError(test.pca$y, yhat.pca))
```

```{r}
InformationValue::plotROC(test.pca$y, yhat.pca)
```

La tecnica della PCA ci consente di ottenere un modello più parsimonioso avendo ridotto notevolmente il numero di regressori, tuttavia i risultati sono considerevolmente peggiori.

### Backward Elimination

Un'altra tecnica utile al contenimento del costo computazionale del modello è la Best Subset Selection, ovvero la selezione del miglior subset di regressori, nel nostro caso valutata sull'AIC. 

```{r}
2
```

```{r}
fit.glm <- glm(y~., train, family="binomial")

glm.backward <- step(fit.glm, direction = "backward", trace=T, k=2)

fit.glm.backward <- glm(glm.backward$formula, train, family = "binomial")

yhat.glm.backward <- predict(fit.glm.backward, test, type="response")

MyConfusionMatrix(test$y, yhat.glm.backward, title = "Logit - Backward Elimination")

cat("Accuracy = ", 1-misClassError(test$y, yhat.glm.backward))
```

Sono state eliminate solamente due variabili: *pct_tl_nvr_dlq* e *num_not_sats*, dopodichè il processo di backward elimination è stato interrotto dall'*AIC stopping rule* poichè non è stato osservato un miglioramento in termini di AUC.

```{r}
InformationValue::plotROC(test$y, yhat.glm.backward)
```

Si osserva come l'AUC sia la stessa del modello base, tuttavia questo modello resta preferibile poichè più parsimonioso.

### Ridge

Proviamo anche l'approccio di regressione penalizzata, con i metodi non-parametrici Ridge e Lasso.

```{r}
X.train <- model.matrix(y~., train)[,-1]
K <- 10
fit.ridge.cv <- cv.glmnet(X.train, train$y, alpha=0, family="binomial", nfolds = K, grouped = FALSE, type.measure = "class", parallel = T)
plot(fit.ridge.cv)
```

Per quanto riguarda la penalizzazione Ridge si seleziona il lambda a $1\sigma$ dal lambda "minimo" per ridurre la varianza del modello il più possibile.

```{r}
X.test <- model.matrix(y~., test)[,-1]

yhat.ridge = predict(fit.ridge.cv, X.test, s = "lambda.1se",  type="response")

MyConfusionMatrix(test$y, yhat.ridge, threshold = 0.5, title = "Ridge Logit")
cat("Accuracy = ", 1-misClassError(test$y, yhat.ridge, threshold = 0.5))
```

```{r}
InformationValue::plotROC(test$y, yhat.ridge)
```

L'AUC ci indica che siamo in presenza di un modello leggermente peggiore del modello base e del modello con backward elimination. 

### Lasso

Ripetiamo quanto visto con la penalizzazione lasso.

```{r}
K <- 10
fit.lasso.cv <- cv.glmnet(X.train, train$y, alpha=1, family="binomial", nfolds = K, grouped = FALSE, type.measure = "class", parallel = T)
plot(fit.lasso.cv)
```

Utilizzando sempre il lambda a $1\sigma$ dal lambda "minimo" si ottiene un modello che scarta 7 variabili per intero e alcuni livelli di altre 2 variabili categoriche (*addr_state* e *purpose*).

```{r}
cat(paste(c("Le variabili escluse dalla selezione Lasso sono:", rownames(coef(fit.lasso.cv, s = "lambda.1se"))[(coef(fit.lasso.cv, s = "lambda.1se") == 0)[,1]]), collapse=" \n" ))
```

```{r}
yhat.lasso <-  predict(fit.lasso.cv, X.test, s = "lambda.1se",  type="response")

MyConfusionMatrix(test$y, yhat.lasso, threshold = 0.5, title="Lasso Logit")
cat("Accuracy = ", 1-misClassError(test$y, yhat.lasso, threshold = 0.5))
```

```{r}
InformationValue::plotROC(test$y, yhat.lasso)
```

L'AUC è molto simile a quella dei migliori modelli già visti ma in questo caso stiamo eliminando ben 7 variabili (e oltre), quindi questo modello è sicuramente il migliore per rapporto tra performance e costo computazionale.

## Random Forest

```{r}
customTuneRF<- function (data, ntree, mtryStart){
  data <- data %>% group_by(y) %>% slice_sample(n=1e5) %>% ungroup() 
  x <- data %>% select(-y)
  y <- data$y
  tuning_data <- data %>% group_by(y) %>% slice_sample(n=5e4) %>% ungroup()
  tuning_x <- tuning_data %>% select(-y)
  tuning_y <- tuning_data$y
  tune <- tuneRF(tuning_x, tuning_y, trace=T, strata=tuning_y, mtryStart=mtryStart, ntreeTry = 50)
  print("Tuning is over!")
  randomForest(x, y, mtry=tune[which.min(tune[, 
      2]), 1], ntree=ntree, strata=y, importance=T, do.trace=T)
}
```

```{r}
fit.rf.150t = customTuneRF(train, ntree=200, mtryStart=7)
```

```{r}
fit.rf.150t$err.rate %>%
  as.data.frame() %>%
  cbind(ntrees=seq(1,nrow(fit.rf.150t$err.rate))) %>%
  rename("Default" = "0", "FullyPaid" = "1", "Overall" = "OOB") %>%
  gather(Error, Value, -ntrees) %>%
  ggplot() +
  geom_line(aes(x=ntrees,y= Value, col=Error)) +
  scale_y_continuous(labels = scales::percent) +
  scale_color_manual(values = c("darkred", "darkgreen", "black")) + 
  labs(x = "# Trees", y = "OOB Error", title = "Random Forest Progression") + 
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 16))
```

Si osserva come il random forest sia ottimizzato con l'utilizzo di 7 regressori (campionati causalmente per ogni albero). Il numero di alberi utilizzati è pari a 200 ma dal secondo plot si osserva come già oltre i 150 alberi l'errore si stabilizzi.

```{r}
fit.rf.150t$importance %>%
  cbind("Variable"=rownames(fit.rf.150t$importance)) %>%
  as.data.frame() %>%
  mutate(MeanDecreaseAccuracy = as.numeric(as.character(MeanDecreaseAccuracy))) %>%
  ggplot() +
  geom_point(aes(x=MeanDecreaseAccuracy, y = reorder(Variable, MeanDecreaseAccuracy), col = MeanDecreaseAccuracy > 0)) +
  scale_color_manual(values=c("red", "black"), guide="none") +
  scale_x_continuous(labels=scales::percent) +
  labs(x= "Mean Decrease Accuracy", y = "", title = "Variables Importance in Random Forest", subtitle = paste("Overall Training Accuracy =", 1-misClassError(fit.rf.150t$y, as.numeric(as.character(fit.rf.150t$predicted)),0.5) )) + 
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 16),
        plot.subtitle = element_text(hjust=0.5,size=12))
```

Si osserva come ci siano alcune variabili che danno un contributo nettamente più importante rispetto alle altre: 
*int_rate*, *term*, *loan_amnt*, *dti*; tuttavia si osserva come tutte le variabili diano un conttributo positivo all'accuracy del modello.

```{r}
yhat.rf = predict(fit.rf.150t, test %>% select(-y), type="prob", norm.votes=T)

MyConfusionMatrix(test$y, yhat.rf[,2], threshold = 0.5)

cat("Accuracy = ", 1-misClassError(test$y, yhat.rf[,2], threshold = 0.5))
```

```{r}
InformationValue::plotROC(test$y, yhat.rf[,2])
```

Il valore dell'AUC ci indica che siamo in presenza del miglior modello finora ottenuto in termini di performance.

## Modello di Cox

In order to perform survival analysis we define three possible outcomes for a lending: "Fully Paid", "Default" and "Pre-Paid", whose meanings are pretty clear.

To distinguish between Regalur Payment and Early Payment we define a tolerance of -1 month since our dates are all represented as month-year.

```{r, message=F}
prep_surv <- function(d, plots=T){
  d <- d %>% 
    as.data.frame() %>%
    mutate(actual_duration_to_term = as.numeric(last_pymnt_d - issue_d) / (as.numeric(substring(as.character(term),0,2))*(365/12)))
  if (plots){
    ht <- ggplot(d) + 
      geom_histogram(aes(x=actual_duration_to_term, y = ..count../sum(nrow(d)), fill=y), bins=50) +
      scale_fill_manual(labels=c("Default", "Fully Paid"), values=c("darkred","darkgreen")) + 
      scale_x_continuous(labels = scales::percent) + 
      scale_y_continuous(labels = scales::percent) + 
      labs(x="Time to end of lending", y = "Percentage of lendings", title="Time to end of lending by outcome") + 
      guides(fill=guide_legend(title="Outcome"))+
      theme_minimal() + 
      theme(plot.title = element_text(hjust = 0.5, size = 16),
          plot.subtitle = element_text(hjust = 0.5, size = 12))
    d_pie <- d %>%
      mutate(y = as.factor(case_when(
        y == 0 ~ 1, ### Default
        (y == 1) & (actual_duration_to_term < 0.8) ~ -1, ### Early Payment
        T ~ 0 ### Regular Payment
      )))
    pie <- piechart(d_pie, "y") +
      scale_fill_manual(labels=c("Regular Payment", "Early Payment", "Default"), values=c("darkgreen",  "darkgray", "darkred"))
  }
  d <- d %>%
    mutate(actual_duration_to_term = ifelse(y==0, actual_duration_to_term, 1)) %>%
    mutate(actual_duration_to_term = ifelse(actual_duration_to_term > 1, 1, actual_duration_to_term)) %>%
      # ignoro gli early payment e i pagamenti in ritardo, settando il tempo a 1 per loro, intendendo che           # questi prestiti sono sopravvissuti fino alla fine.
    mutate(status = ifelse(y==0,1,0)) # status is the opposite of y: status 0 means Fully Paid, status 1 means Default (Failure in Survival Analysis lexicon).
  if (plots) return(list(ht=ht,pie=pie))
  else return(d)
}

set.seed(1000)
train_surv <- sample_frac(acc, 0.7)
test_surv <- anti_join(acc, train_surv)
set.seed(1000)
train_surv <- prep_surv(train_surv, plots=F)
test_surv <- prep_surv(test_surv, plots=F)

ret <- prep_surv(acc, plots=T)
ret$ht
ret$pie
```

```{r}
### Check if everything is as intended

 ggplot(train_surv) + 
      geom_histogram(aes(x=actual_duration_to_term, y = ..count../sum(nrow(train_surv)), fill=as.character(status)), bins=25) +
      scale_fill_manual(labels=c("Fully Paid", "Default"), values=c("darkgreen","darkred")) + 
      scale_x_continuous(labels = scales::percent) + 
      scale_y_continuous(labels = scales::percent) + 
      labs(x="Time to end of lending", y = "Percentage of lendings", title="Time to end of lending by outcome") + 
      guides(fill=guide_legend(title="Outcome"))+
      theme_minimal() + 
      theme(plot.title = element_text(hjust = 0.5, size = 16),
          plot.subtitle = element_text(hjust = 0.5, size = 12))
```

### Survival function

```{r}
fit <- survfit(Surv(actual_duration_to_term, status) ~ 1, data = train_surv)
ggsurvplot(fit, xlab = "Years", legend= "none", ggtheme = theme_minimal())
summary(fit, times = 0.5)
```

### Cox

```{r}
train_surv <- train_surv %>% select(all_of(model_variables), actual_duration_to_term, status) %>% select(-y)
test_surv <- test_surv %>% select(all_of(model_variables), actual_duration_to_term, status) %>% select(-y)
surv_scaling <- preProcess(train_surv %>% select(-status, -actual_duration_to_term), method = c("center", "scale"))
train_surv <- predict(surv_scaling, train_surv)
test_surv <- predict(surv_scaling, test_surv)

train_surv <- train_surv %>% group_by(status) %>% slice_sample(n=min(table(train$y))) %>% ungroup()
```

```{r}
fit <- survfit(Surv(actual_duration_to_term, status) ~ 1, data = train_surv)
ggsurvplot(fit, xlab = "Years", legend= "none", ggtheme = theme_minimal())
summary(fit, times = 0.5)
```

#### Valutare assunzione «Proportional Hazards»

Per valutare l'assunzione di Proportional Hazards per le covariate si procede dapprima con un check visuale della log(-log(Survival)), che valuta l'assunzione di PH per ogni covariata indipendentemente dalle altre, e successivamente ci si serve dei residui Schoenfeld per valutare l'assunzione di PH tenendo conto anche dalle altre covariate (modello multivariato).

1. log[-log(SKM (t))] --- Graphical check

2. Schoenfeld residuals --- Graphical check

##### 1. log[-log(SKM (t))] --- Graphical check

Per l'assunzione di PH abbiamo: $S_X(t) = S_0(t) e^{(\beta' X)}$
che può essere riscritta come: $log(-log(S_X(t))) - log(-log(S_0(t))) = \beta' X$
ne segue che la differenza tra i due logaritmi è costante rispetto al tempo se è valida l'assunzione di PH. 

Questo tipo di verifica può essere fatto unicamente sulle variabili non continue, poiché il $log(-log(S_0(t)))$ deve essere confrontato con $log(-log(S_X(t)))$ per ciascun valore di X su tutto l'intervallo temporale.

```{r}
par(mfrow=c(2,2),mar=c(4,4,2,2))

km.addr_state <- survfit(Surv(actual_duration_to_term, status) ~ addr_state, data=train_surv)
plot(km.addr_state, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of address state")

km.appl_type <- survfit(Surv(actual_duration_to_term, status) ~ application_type, data=train_surv)
plot(km.appl_type, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of application type")

km.emp_length <- survfit(Surv(actual_duration_to_term, status) ~ emp_length, data=train_surv)
plot(km.emp_length, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of employment length")

km.home_ownership <- survfit(Surv(actual_duration_to_term, status) ~ home_ownership, data=train_surv)
plot(km.addr_state, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of home ownership")

km.init_list <- survfit(Surv(actual_duration_to_term, status) ~ initial_list_status, data=train_surv)
plot(km.init_list, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of initial list status")

km.purpose <- survfit(Surv(actual_duration_to_term, status) ~ purpose, data=train_surv)
plot(km.purpose, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of purpose")

km.term <- survfit(Surv(actual_duration_to_term, status) ~ term, data=train_surv)
plot(km.term, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of term")

km.ver_status <- survfit(Surv(actual_duration_to_term, status) ~ verification_status, data=train_surv)
plot(km.ver_status,fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of verification status")

km.fico_class <- survfit(Surv(actual_duration_to_term, status) ~ fico_class, data=train_surv)
plot(km.fico_class, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of fico class")
```

L'assunzione di PH pare valere per tutte le variabili categoriche, mentre sembra che non valga per la "fico class".

##### 2. Schoenfeld residuals --- Graphical check

I residui Schoenfeld sono definiti come: $r_j = x_j - E[x_j|R_j]$ \
dove $x_j$ è la covariata dell'individuo che *fallisce* al tempo $t_{(j)}$ e $R_j$ è il risk set al tempo $t_{(j)}$.
Ci si aspetta che il valore atteso dei residui sia 0, ne segue che l'andamento dei residui rispetto al tempo deve essere costante. Si plottano i residui Schoenfeld standardizzati.


```{r}
model.cox.base <- coxph(Surv(actual_duration_to_term, status) ~ ., data = train_surv)
czph <- cox.zph(model.cox.base, terms = F)

par(mfrow=c(3,3),mar=c(4,4,2,2))
plot(czph, resid=FALSE)
```

Per molte variabili non vale l'assunzione di PH, le escludiamo. Alcune, sebbene graficamente sarebbero da escludere, sono invece tenute per via della scala.

###
Ad esempio beta(t) di annual_inc è chiaramente non costante, tuttavia la variazione avviene su un ordine di grandezza di 1e-6 !!! 
###

```{r}
train_ph <- train_surv %>% select(-application_type, -initial_list_status, -int_rate, -num_rev_tl_bal_gt_0, -pct_tl_nvr_dlq, -purpose, -revol_bal, -revol_util, -term, -total_acc, -verification_status, -mo_sin_earliest_cr_line, -num_bc_not_sats, -home_ownership, -addr_state)
```

```{r}
model.cox.ph <- coxph(Surv(actual_duration_to_term, status) ~ ., train_ph, x=T,y=T)
formula.cox.ph <- paste(names(model.cox.ph$coefficient), collapse = "+")
  
model.cox.strata <- coxph(
  Surv(actual_duration_to_term, status) ~
    dti +
    delinq_2yrs +
    emp_length +
    loan_amnt +
    mo_sin_old_il_acct +
    mort_acc+num_bc_tl +
    num_op_rev_tl +
    open_acc +
    percent_bc_gt_75 +
    pub_rec +
    tax_liens +
    fico_class +
    num_not_sats + 
    survival::strata(application_type) +
    survival::strata(initial_list_status) +
    survival::strata(purpose) +
    survival::strata(term) +
    survival::strata(verification_status) +
    survival::strata(home_ownership) +
    survival::strata(addr_state),
  train_surv, x =T, y=T) 
summary(model.cox.strata)
```


### Functional form of contiuous variables

```{r}
library(splines)
mar.res<-resid(model.cox.base,type='martingale')

for (variable in model_num_variables){
  ms <- coxph(Surv(actual_duration_to_term, status>0) ~ ns(eval(as.name(variable)),knots=c(-1,0,1)), data = train_surv) # ns natural cubic splines, e knots sono i nodi delle splines.
  pred <- predict(ms, type="terms", se=TRUE) # terms indica che voglio beta * x
  hfit <- pred$fit[,1]
  hse <- pred$se[,1]
  hmat <- cbind(hfit, hfit+1.96*hse,hfit-1.96*hse)
  o <- order(train_surv[[variable]])
  matplot(train_surv[[variable]][o], hmat[o, ], pch="*",col=c("red","orangered","orangered"), lwd=c(2,1,1),xlab = variable, ylab="log hazard ratio",main=paste("Check functional form of",variable),type="l")
  
  ms <- coxph(Surv(actual_duration_to_term, status) ~ eval(as.name(variable)), data = train_surv) # ns natural cubic splines, e knots sono i nodi delle splines.
  pred <- predict(ms, type="terms", se=TRUE) # terms indica che voglio beta * x
  hfit <- pred$fit[,1]
  hse <- pred$se[,1]
  hmat <- cbind(hfit, hfit+1.96*hse,hfit-1.96*hse)
  o <- order(train_surv[[variable]])
  matplot(train_surv[[variable]][o], hmat[o, ], pch="*",col=c("blue","cornflowerblue","cornflowerblue"), lwd=c(2,1,1),type="l", add=T)
  legend("topright",c("natural spline","linear"),col=c(2,4),lwd=2,bty="n")
}
```

### Calibration

Si procede con la costruzione dei modelli, specificando l'opzione x = TRUE per poter poi utilizzare la funzione Score del pacchetto riskRegression.
Creo un modello aumentato con le variabili per cui non vale PH.


```{r}
score <- Score(list("PH model"=model.cox.ph,"Stratified Model"=model.cox.strata),
              formula=Surv(actual_duration_to_term, status)~1,
              data=train_surv, conf.int=F,
              times=seq(0.1,0.9,0.2),
              plots=c("calibration","ROC"),
              progress.bar=1)
```

Si decide di prendere il time-point a metà del termine e si valutano le performance dei modelli sui tre aspetti: calibrazione, discriminazione, net benefit.

Per valutare la calibrazione dei modelli si usano insieme il Calibration Plot e il Brier Score.

```{r}
plotCalibration(score,times=0.5, cens.method="local",method="quantile", q=20, auc.in.legend = F)
title(main="Calibration at half term")
```

### Discrimination

```{r}
plotROC(score,times=0.1,cens.method="local")
plotROC(score,times=0.5,cens.method="local")
plotROC(score,times=0.9,cens.method="local")

title(main="time-dependent ROC at half term")
```

### Predictions

```{r}
#rm(list=setdiff(ls(), c("train_surv", "test_surv", "train", "test", "yhat.glm.under", "yhat.backward", "yhat.lasso", "yhat.ridge", "yhat.rf", "model.cox.base", "model.cox.strata")))

yhat.cox.strata <- c()
for (i in (seq(1,nrow(test_surv),ceiling(nrow(test_surv)/10))-1)){
  fit.cox.strata<-survfit(model.cox.strata,newdata=test_surv[(i+1):(i+ceiling(nrow(test_surv)/10)),])
  yhat <- as.numeric(summary(fit.cox.strata,times=1)$surv)
  yhat.cox.strata <- c(yhat.cox.strata,yhat)
  print(paste0("Processed ", i/nrow(test_surv)*100, "%"))
}

InformationValue::misClassError((1-test_surv$status), yhat.cox.strata)

MyConfusionMatrix(as.factor(as.character(1-test_surv$status)), yhat.cox.strata, threshold = 0.5)

plotROC(score,times=1,cens.method="local")
```


# Conclusioni


```{r}
score <- Score(list("LogReg"=fit.glm,
                    "LogReg PCA"=fit.pca,
                    "LogRidge"=fit.ridge.cv,
                    "LogRegLasso"=fit.lasso.cv,
                    "RandFor"=fit.rf.150t),
              formula=y~1,
              data=test, conf.int=F,
              plots=c("calibration","ROC"),
              progress.bar=1)

score <- Score(list("LogReg"=fit.glm),
              formula=y~1,
              data=test, conf.int=F,
              plots=c("calibration","ROC"),
              progress.bar=1)

plotCalibration(score,times=0.5, cens.method="local",method="quantile", q=20, auc.in.legend = F)
title(main="Calibration at half term")
```

```{r fig.width=10, fig.height=6}
plot_precision_at_k(test$y, list("Logit UnderSampling"=yhat.glm.under, "Logit PCA"=yhat.pca, "Logit Backward Elimination"=yhat.glm.backward, "Logit Ridge"=unname(yhat.ridge), "Logit Lasso"=unname(yhat.lasso),"Random Forest"=yhat.rf[,2], "Cox"=yhat.cox.strata))
```


```{r}
stopCluster(cl)
```

