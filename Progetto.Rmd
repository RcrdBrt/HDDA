---
title: "Progetto HDDA AA2021/2022"
output: html_notebook
---

# Libraries

```{r message=FALSE, warning=FALSE, paged.print=FALSE, include=F}
if(!require(data.table)) install.packages("data.table")
if(!require(tibble)) install.packages("tibble")
if(!require(Hmisc)) install.packages("Hmisc")
if(!require(dplyr)) install.packages("dplyr")
if(!require(ggplot2)) install.packages("ggplot2")
if(!require(scales)) install.packages("scales")
if(!require(tidyr)) install.packages("tidyr")
if(!require(corrplot)) install.packages("corrplot")
if(!require(lubridate)) install.packages("lubridate")
if(!require(stringr)) install.packages("stringr")
if(!require(sampling)) install.packages("sampling")
if(!require(leaps)) install.packages("leaps")
if(!require(bestglm)) install.packages("bestglm")
if(!require(glmnet)) install.packages("glmnet")
if(!require(factoextra)) install.packages("factoextra")
if(!require(caret)) install.packages("caret")
if(!require(ranger)) install.packages("ranger")
if(!require(randomForest)) install.packages("randomForest")
if(!require(InformationValue)) install.packages("InformationValue")
if(!require(kernlab)) install.packages("kernlab")
if(!require(e1071)) install.packages("e1071")
if(!require(survival)) install.packages("survival")
if(!require(survminer)) install_github("kassambara/survminer", build_vignettes = FALSE)
if(!require(riskRegression)) install.packages("riskRegression")
if(!require(parallel)) install.packages("doParallel")
if(!require(doMC)) install.packages("doMC")
if(!require(patchwork)) install.packages("patchwork")

library(data.table)
library(tibble)
library(Hmisc)
library(tidyr)
library(dplyr)
library(ggplot2)
library(corrplot)
library(lubridate)
library(stringr)
library(sampling)
library(leaps)
library(bestglm)
library(glmnet)
library(factoextra)
library(caret)
library(ranger)
library(randomForest) 
library(InformationValue) 
library(kernlab) 
library(e1071) 
library(survival)
library(riskRegression)
library(parallel)
library(doMC)
library(pander)
library(patchwork)
library(car)

`%notin%` <- Negate(`%in%`)

registerDoMC(cores = detectCores())
#cl = makePSOCKcluster(detectCores())
#registerDoParallel(cl)

piechart <- function(d, group, legend_title = "Outcome"){
  piepercent <- d %>% 
    group_by((!!sym(group))) %>% 
    summarise(n_group = n()) %>% 
    mutate(n_perc= round( n_group/nrow(d)* 100,2))
  
  ggplot(piepercent, aes(x = "", y = n_perc, fill = !!sym(group))) +
    geom_bar(width = 1, stat = "identity", color = "white") +
    coord_polar("y", start = 0) +
    geom_text(aes(label = n_perc), position = position_stack(vjust = 0.5),color = "white")+
    guides(fill=guide_legend(title=legend_title))+
    theme_void()
}


MyConfusionMatrix <- function(actuals, predictions, threshold=0.5, title=""){
  cm <- caret::confusionMatrix(as.factor(ifelse(predictions>threshold,1,0)), actuals, threshold, dnn=c("Prediction", "Actual"), positive="1", mode="prec_recall")
  ggplot(as.data.frame(cm$table), aes(Actual, Prediction, fill= Freq)) +
    geom_tile() + geom_text(aes(label=Freq), fontface="bold") +
    scale_fill_distiller(palette="Greens",guide="none", direction = 1) +
    labs(x = "Actual",y = "Prediction", title=title, subtitle=
           paste(
             "Precision at 0.5 threshold:",
             round(precision(actuals,predictions,threshold),3)*100, "%")) +
    scale_x_discrete(labels=c("Default", "Fully Paid")) +
    scale_y_discrete(labels=c("Fully Paid","Default"), limits=rev) +
    theme_minimal() + 
    theme(plot.title = element_text(hjust = 0.5, size = 16),
          plot.subtitle = element_text(hjust = 0.5, size = 12)) 
}


plot_precision_vs_npred <- function(actuals, predictions, title=""){ ### non serve più, cancellare T.T
  p <- vector("list", length(predictions))
  names(p) <- names(predictions)
  n <- vector("list", length(predictions))
  names(n) <- names(predictions)
  for (i in 1:length(predictions)){
      for (threshold in seq(0,1,0.01)){
        p[[i]] <- c(p[[i]],precision(actuals, predictions[[i]], threshold = threshold))
        n[[i]] <- c(n[[i]],length(predictions[[i]][predictions[[i]] >= threshold]))
      }
  }
  
  res <- as.data.frame(list(p=p,n=n))
  res$i <- 1:nrow(res)
  res <- gather(res,var,val,-i) %>% separate(var, c("variable", "Model")) %>% reshape(idvar = c("i","Model"), timevar = "variable", direction = "wide")
  names(res)[c(3,4)] <- c("p","n")
  
  res <- res %>% arrange(Model, p)
  plotly::plot_ly(res) %>%
  plotly::add_trace(x=~p*100, y = ~n/length(actuals)*100, yaxis="y", type="scatter", mode = "lines+markers", color=~Model, opacity = 1) %>% 
  plotly::add_trace(x=~p*100, y = ~round(n/length(actuals)*4e4), yaxis="y2", type="scatter", mode = "lines+markers", color=~Model, opacity = 0, showlegend=F) %>%     
  plotly::layout(title = "Results",
                 xaxis = list(title = 'Precision',  ticksuffix = "%"),
                 yaxis = list(title = 'Percentage of predicted Fully Paid', ticksuffix = "%", gridcolor=rgb(0, 0, 0, max = 255, alpha = 80)),
                 yaxis2= list(tickfont = list(color = "red"), gridcolor=rgb(255, 0, 0, max = 255, alpha = 20), overlaying = "y",side = "right", automargin = T,title = "Number of predicted Fully Paid"),
                 legend = list(x=0.7,y=0.9))

}

precision_at_k <- function(actuals, predictions){
  d <- data.frame(actuals = actuals, score = predictions) %>%
    arrange(-score)
  d$k <- 1:nrow(d)
  p_at_k <- rep(0,nrow(d))
  n_relevant <- 0
  for (k in 1:nrow(d)){
    if (d[k,"actuals"] == 1){
      n_relevant <- n_relevant+1
    }
    p_at_k[k] <- n_relevant/k
  }
  p_at_k
}

plot_precision_at_k <- function(actuals, predictions, resolution_k=100){
  test_size <- length(actuals)
  p_at_k <- vector("list", length(predictions))
  names(p_at_k) <- names(predictions)
  for (i in 1:length(predictions)){
    p_at_k[[i]] <- precision_at_k(actuals, predictions[[i]])
  }
  p_at_k <-  p_at_k %>% 
    sapply('[', seq(max(sapply(p_at_k, length)))) %>% 
    as.data.frame()
  p_at_k <- p_at_k %>%
    mutate(k=1:nrow(p_at_k)) %>%
    gather(Model, p,-k) %>%
    filter( k == 1 | k %% resolution_k == 0)
  plotly::plot_ly(p_at_k) %>%
  plotly::add_trace(x=~round(k/test_size*100,3), y = ~p*100, type="scatter", mode = "lines+markers", color=~Model) %>% 
  plotly::add_trace(x=~round(k/test_size*4e4), y = ~p*100, xaxis="x2", type="scatter", mode = "lines+markers", color=~Model, opacity = 0, showlegend=F) %>%     
  plotly::layout(xaxis = list(title = 'K', ticksuffix= "%", gridcolor=rgb(0, 0, 0, max = 255, alpha = 60)),
                 xaxis2= list(tickfont = list(color = "red"), gridcolor=rgb(255, 0, 0, max = 255, alpha = 20), overlaying = "x",side = "top", automargin = T, title = list(text="Expected K")),
                 yaxis = list(title = 'Precision @ K', ticksuffix = "%", gridcolor=rgb(0, 0, 0, max = 255, alpha = 60)),
                 legend = list(x=0.8,y=0.9))
} 
```


# Data Ingestion

```{r message=FALSE, warning=FALSE, cache=TRUE, paged.print=FALSE}
acc_full <- fread("archive/accepted_2007_to_2018Q4.csv", sep = ",", header = T)
```

Il dataset utilizzato proviene da [kaggle](https://www.kaggle.com/wordsforthewise/lending-club). Sono stati considerati soltanto i prestiti che sono stati erogati contenuti nel file: accepted_2007_to_2018Q4.csv.
In origine il dataset complessivo contiene 151 variabili e 2260701 osservazioni.

{r message=FALSE, warning=FALSE, cache=TRUE, paged.print=FALSE}
acc_full <- fread("archive/accepted_2007_to_2018Q4.csv", sep = ",", header = T)


Di seguito viene fornito un elenco delle variabili selezionate in fase di data preparation. Al meglio delle conoscenze, esse fornite per la maggior parte dal cliente in fase di registrazione sulla piattaforma LendingClub.

Variabile|Tipo|Significato
-|-|-
addr_state|Fattore|Indica lo Stato di provenienza del richiedente
annual_inc|Int|Il reddito annuale fornito dal richiedente
application_type|Fattore|Un fattore esprimente se il richiedente è un individuo singolo oppure è una richiesta proveniente da più persone
delinq_2yrs|Int|Il numero di insolvenze rateali superiori a 30 giorni segnalate negli ultimi 2 anni nel registro di credito del richiedente
earliest_cr_line|Date|Data in cui il richiedente ha aperto la sua prima linea di credito
emp_length|Int|Durata dell'impiego in anni. Il valore varia tra 0 e 10, dove 10 indica 10 o più anni
fico_range_high|Fattore|Estremo superiore dell'intervallo FICO del richiedente
fico_range_low|Fattore|Estremo inferiore dell'intervallo FICO
grade|Fattore|Score assegnato da parte di LendingClub al richiedente
home_ownership|Fattore|Indica se il richiedente è proprietario di un immobile o è in affitto
initial_list_status|Fattore|Copertura del prestito da parte di un singolo investitore o meno
int_rate|Float|Tasso del prestito
issue_d|Date|Data in cui i fondi sono stati erogati
last_pymnt_d|Date|Data dell'ultimo pagamento
loan_amnt|Int|Importo richiesto
funded_amnt|Int|Importo erogato
loan_status|Fattore|Stato del prestito (in corso, default, in ritardo, ...)
mo_sin_old_il_acct|Int|Mesi trascorsi dalla più vecchia linea di credito bancaria
mo_sin_old_rev_tl_op|Int|Mesi trascorsi dall'apertura del più vecchio conto revolving
mort_acc|Int|Numero di mutui intestati al richiedente
num_bc_sats|Int|Numero di solvenze degli estratti conto delle carte di credito del cliente
num_bc_tl|Int|Numero delle carte del cliente
num_op_rev_tl|Int|Numero di carte revolving del cliente
num_rev_accts|Int|Numero di conti revolving
num_rev_tl_bal_gt_0|Int|Numero di transazioni revolving con saldo maggiore di 0
num_sats|Int|Numero di linee di credito solventi intestate al richiedente
open_acc|Int|Numero di linee di credito aperte
pct_tl_nvr_dlq|Int|Percentuale di rinnovi di credito solventi
percent_bc_gt_75|Int|Percentuale di carte di credito sopra al massimale di oltre il 75%
pub_rec|Int|Numero di ritardi di pagamento
pub_rec_bankruptcies|Factor|Numero di volte in cui il cliente ha dichiarato bancarotta
purpose|Factor|Motivo del prestito, espresso dal richiedente
revol_bal|Int|Saldo totale del credito revolving
revol_util|Int|Percentuale di utilizzo del credito revolving da parte del richiedente
sub_grade|Factor|Rate del prestito, assegnato da LendingClub
tax_liens|Int|Numero di ipoteche intestate al richiedente
term|Int|Numero di rate, durata del prestito
total_acc|Int|Numero di prestiti in corso al momento della richiesta
verification_status|Factor|Informazioni fornite dal richiedente sono state verificate o meno

```{r, cache=TRUE}
variables <- c(
  "addr_state",
  #"annual_inc",
  "dti",
  "application_type",
  "delinq_2yrs",
  "earliest_cr_line",
  "emp_length",
  #"emp_title", # troppi livelli, circa 600k
  "fico_range_high",
  "fico_range_low",
  "grade",
  "home_ownership",
  "initial_list_status",
  "int_rate",
  "issue_d",
  "last_pymnt_d",
  "loan_amnt",
  "funded_amnt",
  "loan_status",
  "mo_sin_old_il_acct",
  "mo_sin_old_rev_tl_op",
  "mort_acc",
  "num_bc_sats",
  "num_bc_tl",
  "num_op_rev_tl",
  "num_rev_accts",
  "num_rev_tl_bal_gt_0",
  "num_sats",
  "open_acc",
  "pct_tl_nvr_dlq",
  "percent_bc_gt_75",
  "pub_rec",
  "pub_rec_bankruptcies",
  "purpose",
  "revol_bal",
  "revol_util",
  "sub_grade",
  "tax_liens",
  "term",
  "total_acc",
  "verification_status"
)
```

```{r}
acc <- acc_full
acc <- acc[,..variables]
acc <- acc[complete.cases(acc),]
acc <- acc[!apply(acc, 1, function(x) any(x=="")),]
fwrite(acc, "archive/accepted_clean.csv", sep = ",")
```

# Data Preparation

Dopo un'attenta analisi, alcune tra le variabili categoriche selezionate offrono un'elevato numero di livelli. Data la quantità di osservazioni, si modificano alcune variabili al fine di diminuire il numero di livelli che presentano. In particolare, loan_status viene trasformata in un fattore a 2 livelli: 0 se il prestito è in stato di default o in forte ritardo con i pagamenti, 1 se invece è stato rimborsato con successo. Il dataset inoltre presenta una variabile geografica (addr_state), indicante lo stato di provenienza del richiedente che è stata ridotta a 7 livelli raggruppanti le macro-aree geografiche degli Stati Uniti (West Coast, Midwest, ...). Un'altra motivazione per la riduzione del numero dei livelli è la riduzione dello sbilanciamento inter-classe. Ad esempio, la variabile purpose è stata ridotta da 15 a 3 livelli mantenendo i 2 più numerosi e accorpando tutti gli altri livelli (nella classe other).

```{r}
acc <- fread("archive/accepted_clean.csv", sep=",",header=T)
acc <- as.data.frame(acc)
numeric_variables <- c(
  #"annual_inc",
  "dti",
  "delinq_2yrs",
  "mo_sin_earliest_cr_line",
  "fico_range_high",
  "fico_range_low",
  "int_rate",
  "loan_amnt",
  "funded_amnt",
  "mo_sin_old_il_acct",
  "mo_sin_old_rev_tl_op",
  "mort_acc",
  "num_bc_sats",
  "num_bc_tl",
  "num_op_rev_tl",
  "num_rev_accts",
  "num_rev_tl_bal_gt_0",
  "num_sats",
  "open_acc",
  "pct_tl_nvr_dlq",
  "percent_bc_gt_75",
  "pub_rec",
  "pub_rec_bankruptcies",
  "revol_bal",
  "revol_util",
  "tax_liens",
  "total_acc"
)

acc <- acc %>%
  mutate(
    mo_sin_earliest_cr_line=as.integer(round((as.Date("2018-12-01")-lubridate::my(earliest_cr_line))/(365.25/12))),
    issue_d = lubridate::my(issue_d),
    last_pymnt_d = lubridate::my(last_pymnt_d),
    emp_length=as.numeric(str_extract(emp_length, "[0-9]+"))
  ) %>%
  mutate(
    emp_length = case_when(
      emp_length < 5 ~ "low",
      emp_length < 10 ~ "mid",
      T ~"high")) %>%
  select(-earliest_cr_line)

acc_with_current <- acc

acc <- acc %>% 
  filter(loan_status %notin% c("Current", "In Grace Period", "Late (16-30 days)")) %>%
  mutate(y=case_when(
    loan_status == "Late (31-120 days)" ~ 0,
    loan_status == "Charged Off" ~ 0,
    loan_status == "Default" ~ 0,
    loan_status == "Fully Paid" ~ 1
  )) %>%
  mutate(addr_state=case_when(
    addr_state %in% c("WA", "OR", "CA", "HI", "AL", "AK") ~ "West Coast",
    addr_state %in% c("MT", "ID", "NV", "UT", "CO", "WY") ~ "The Rocky Mountains",
    addr_state %in% c("AZ", "NM", "TX", "OK") ~ "South West",
    addr_state %in% c("ND", "SD", "NE", "KS", "MN", "IA", "MO", "WI", "IL", "IN", "MI", "OH") ~ "Midwest",
    addr_state %in% c("AR", "LA", "MS", "KY", "TN", "AL", "GA", "FL", "NC", "SC", "VA", "WV") ~ "South East",
    addr_state %in% c("ME", "VT", "NH", "MA", "RI", "CT") ~ "New England",
    addr_state %in% c("NY", "PA", "NJ", "MD", "DE", "DC") ~ "Mid Atlantic",
  )) %>%
  # livelli erano molto sbilanciati, optato per 3 livelli
  mutate(purpose=case_when(
    purpose %in% c("debt_consolidation") ~ "debt_consolidation",
    purpose %in% c("credit_card") ~ "credit_card",
    T ~ "other"
  )) %>% 
  mutate(
    addr_state=as.factor(addr_state),
    y=as.factor(y),
    application_type=as.factor(application_type),
    emp_length=as.factor(emp_length),
    grade=as.factor(grade),
    home_ownership=as.factor(home_ownership),
    initial_list_status=as.factor(initial_list_status),
    purpose=as.factor(purpose),
    sub_grade=as.factor(sub_grade),
    term=as.factor(term),
    verification_status=as.factor(verification_status)
  ) %>% 
  filter(home_ownership %notin% c("ANY", "NONE", "OTHER"))  %>%
  mutate(home_ownership = as.factor(as.character(home_ownership))) %>% # remove empty levels
  select(-loan_status)
set.seed(1000)
source("data_preparation/outliers.R", print.eval = T)
```

Possiamo pensare di utilizzare anche i Current tipo con 90% già ripagato. Ma ci servono? No!

# Data Exploration

### Numero di osservazioni / tempo

```{r, fig.width=10, fig.height=6}
month_summary_with_current <- 
  acc_with_current %>% 
  group_by(issue_d) %>% 
  summarise(n_current= n())

month_summary <- 
  acc %>% 
  group_by(issue_d) %>% 
  summarise(n = n())

month_summary_full <- 
  acc_full %>% 
  mutate(issue_d = lubridate::my(issue_d)) %>%
  group_by(issue_d) %>% 
  summarise(n_full= n()) %>%
  left_join(month_summary_with_current) %>%
  left_join(month_summary) 

plotly::plot_ly(month_summary_full, x = ~issue_d) %>% 
  plotly::add_trace(y = ~n_full, mode = "lines+markers", name = "All", opacity = 0.2) %>%
  plotly::add_trace(y = ~n_current, mode = "lines+markers", name = "No Missing Values", opacity = 0.5) %>%
  plotly::add_trace(y = ~n, mode = "lines+markers", name = "No Missing Values and No Current", opacity = 1) %>%
  plotly::layout(title = "Crescita di LendingClub",  xaxis = list(title = 'Data'),
                 yaxis = list(title = 'Numero prestiti finanziati'),
                 legend = list(x=0.1,y=0.9))
rm(acc_full)
rm(acc_with_current)
```

### Pie chart default vs fully paid

```{r}
piechart(acc,group="y") +
  scale_fill_manual(labels=c("Default", "Fully Paid"), values=c("darkred","darkgreen"))
```

### ROI boxplot/violinplot (for each grade?)

```{r}
source("data_preparation/ROI_violin.R", print.eval = T)
```


### Violin plot for each numeric variable and barplot for categorical variables

```{r, fig.width=10, fig.height=6}
source("data_preparation/all_violin.R", print.eval = T)
```


### Investigate correlations and fix


```{r}
corrplot(cor(acc[,numeric_variables]))
```

```{r}
cor.mtest <- function(mat, ...) {
    mat <- as.matrix(mat)
    n <- ncol(mat)
    p.mat<- matrix(NA, n, n)
    diag(p.mat) <- 0
    for (i in 1:(n - 1)) {
        for (j in (i + 1):n) {
            tmp <- cor.test(mat[, i], mat[, j], ...)
            p.mat[i, j] <- p.mat[j, i] <- tmp$p.value
        }
    }
  colnames(p.mat) <- rownames(p.mat) <- colnames(mat)
  p.mat
}
# matrix of the p-value of the correlation
chart_pic_file = tempfile(pattern="file", tmpdir=tempdir(), fileext = ".png")
p.mat <- cor.mtest(acc[,numeric_variables])
col <- colorRampPalette(c("#BB4444", "#EE9988", "#FFFFFF", "#77AADD", "#4477AA"))
png(filename = chart_pic_file, width = 900, height = 900, type = "cairo")
corrplot::corrplot(cor(acc[,numeric_variables]), method="color", col=col(200),  
         type="upper", 
         addCoef.col = "black", # Add coefficient of correlation
         tl.col="black", tl.srt=45, tl.cex = .7, number.cex=0.75,  #Text label color and rotation
         # Combine with significance
         p.mat = p.mat, sig.level = 0.2, insig = "blank", 
         # hide correlation coefficient on the principal diagonal
         diag=T 
         )
```

```{r pressure, out.width= '100%'}
knitr::include_graphics(chart_pic_file)
```


# Fix Correlation

```{r}
### categorizzazione fico_mean (https://www.investopedia.com/terms/f/ficoscore.asp)
acc <- acc %>% 
  mutate(fico_mean = (fico_range_high+fico_range_low)/2) %>%
  select(-fico_range_high, -fico_range_low) %>% 
  mutate(fico_class=case_when(
    fico_mean <= 580 ~ "Poor",
    fico_mean > 580 & fico_mean <= 669 ~ "Fair",
    fico_mean > 670 & fico_mean <= 739 ~ "Good",
    fico_mean > 740 & fico_mean <= 799 ~ "Very Good",
    fico_mean > 800 ~ "Exceptional"
  )) %>% select(-fico_mean) %>% mutate(fico_class=as.factor(fico_class))

acc <- acc %>% 
  mutate(num_not_sats = (open_acc - num_sats)/open_acc,
         num_bc_not_sats = (num_bc_tl - num_bc_sats)/num_bc_tl) %>%
  select(-num_sats, num_bc_sats)

# tolte le correlazioni, restano queste variabili esplicative numeriche
new_numeric_variables <- c(
  #"annual_inc",
  "dti",
  "delinq_2yrs",
  "mo_sin_earliest_cr_line",
  "int_rate",
  "loan_amnt",
  "mo_sin_old_il_acct",
  "mo_sin_old_rev_tl_op",
  "mort_acc",
  "num_bc_not_sats",
  "num_bc_tl",
  "num_op_rev_tl",
  "num_rev_accts",
  "num_rev_tl_bal_gt_0",
  "num_not_sats",
  "open_acc",
  "pct_tl_nvr_dlq",
  "percent_bc_gt_75",
  "pub_rec",
  "pub_rec_bankruptcies",
  "revol_bal",
  "revol_util",
  "tax_liens",
  "total_acc"
)
corrplot(cor(acc[, new_numeric_variables]))
```


# Modeling

```{r}
model_variables <-  names(acc)[names(acc) %notin% c(
  "grade",
  "funded_amnt",
  "issue_d",
  "last_pymnt_d",
  "num_sats",
  "num_bc_sats",
  "sub_grade",
  "pub_rec_bankruptcies",
  "num_rev_accts",
  "mo_sin_old_rev_tl_op"
)]

model_num_variables <- model_variables[model_variables %in% new_numeric_variables]

model_acc <- acc[,model_variables] %>% relocate(y, .after = last_col())

#model_acc[, model_num_variables] <- scale(model_acc[, model_num_variables])

corrplot(cor(model_acc[, model_num_variables]))
```

```{r message=F}
set.seed(1000)
train <- sample_frac(model_acc, 0.7)
test <- anti_join(model_acc,train)

scaling <- preProcess(train, method = c("center", "scale"))
train <- predict(scaling,train)
test <- predict(scaling, test)
```

To deal with class imbalance we define weights so that the model's predictions will be fair to both classes.

```{r}
model_weights <- ifelse(train$y == "0",
                        (1/table(train$y)[1]) * 0.5, ### (1 / numero osservazioni classe 0) / 2
                        (1/table(train$y)[2]) * 0.5) ### (1 / numero osservazioni classe 1) / 2
# sum(model_weights) == 1 TRUE
```

## Logistic Regression

### Plain

```{r}
fit.glm.unbalanced <- glm(y~., train, family="binomial")
#vif(fit.glm.unbalanced)
yhat.glm.unbalanced <- predict(fit.glm.unbalanced, test, type="response")
cat("Accuracy of Unbalanced Model:", 1-misClassError(test$y, yhat.glm.unbalanced))
```

```{r}
set.seed(1000)
train.under <- train %>% group_by(y) %>% slice_sample(n=min(table(train$y))) %>% ungroup()
fit.glm.under <- glm(y~., train.under, family="binomial")
yhat.glm.under<- predict(fit.glm.under, test, type="response")
cat("Accuracy of UnderSampling Model:", 1-misClassError(test$y, yhat.glm.under))
```

```{r}
fit.glm.weighted <- glm(y~., train, family="binomial", weights=model_weights)
yhat.glm.weighted <- predict(fit.glm.weighted, test, type="response")
cat("Accuracy of Balanced Model:", 1-misClassError(test$y, yhat.glm.weighted))
```


```{r fig.width=10, fig.height=4}
p1 <- MyConfusionMatrix(test$y, yhat.glm.unbalanced, title="Logit Unbalanced")
p2 <- MyConfusionMatrix(test$y, yhat.glm.under, title="Logit UnderSampling")
p3 <- MyConfusionMatrix(test$y, yhat.glm.weighted, title="Logit Weighted")

p1+p2+p3
```

```{r}
plot_precision_at_k(test$y, list("glmunbalanced"=yhat.glm.unbalanced, "glmundersampling"=yhat.glm.under, "glmweighted"=yhat.glm.weighted))
```

L'utilizzo dei pesi ci permette di avere previsioni più bilanciate. Al costo di peggiorare l'accuracy totale del nostro modello si riescono ad ottenere previsioni più attendibili sulla classe minoritaria (Default). Nonostante questo effetto sia minimo, come si nota nell'ultimo grafico, esso è presente il che ci guida verso la scelta di un train set bilanciato tramite undersampling, tramite il quale si ottengono dei modelli più efficaci e al contempo più parsimoniosi. 

```{r}
InformationValue::plotROC(test$y, yhat.glm.under)
```

```{r}
train <- train.under
```

### PCA

```{r}
pca.res <- prcomp(train[, model_num_variables])

p1 <- ggplot()+
  geom_point(aes(x=1:length(pca.res$sdev), y=pca.res$sdev, col=pca.res$sdev<1)) +
  geom_line(aes(x=1:length(pca.res$sdev),y=1), color="red") + 
  geom_text(aes(x=1:length(pca.res$sdev), y=pca.res$sdev+0.1, label=1:length(pca.res$sdev))) +
  scale_color_manual(values = c("red", "blue"), guide="none") +
  labs(x="Component", y="Standard Deviation", title = "PCA components") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 16))

p2 <- fviz_eig(pca.res, chioce="eigenvalue", ggtheme = theme_minimal() + theme(plot.title = element_text(hjust = 0.5, size = 16)))
p1+p2
```

```{r}
train.pca <- as.data.frame(as.matrix(train[,model_num_variables]) %*% pca.res$rotation)[,1:7] # prime sette variabili
test.pca <- as.data.frame(as.matrix(test[,model_num_variables]) %*% pca.res$rotation)[,1:7] # prime sette variabili

train.pca$y <- train$y
test.pca$y <- test$y
```

```{r}
fit.pca <- glm(y~., train.pca, family="binomial")

yhat.pca <- predict(fit.pca, test.pca, type="response")

MyConfusionMatrix(test.pca$y, yhat.pca, title = "Logit - PCA")

cat("Accuracy = ", 1-misClassError(test.pca$y, yhat.pca))
```

```{r}
InformationValue::plotROC(test.pca$y, yhat.pca)
```

Cerchiamo quindi altri metodi blah blah.

### Backward Elimination

```{r}
#train.tiny <- train %>% slice_sample(n=5e4) %>% ungroup()

fit.glm <- glm(y~., train, family="binomial")

glm.backward = step(fit.glm, direction = "backward", trace=T, k=2)

fit.glm.backward <- glm(glm.backward$formula, train, family = "binomial")

yhat.glm.backward = predict(fit.glm.backward, test, type="response")

MyConfusionMatrix(test$y, yhat.glm.backward, title = "Logit - Backward Elimination")

cat("Accuracy = ", 1-misClassError(test$y, yhat.glm.backward))
```

```{r}
InformationValue::plotROC(test$y, yhat.glm.backward)
```



### Ridge

```{r}
X.train <- model.matrix(y~., train)[,-1]
K <- 10
fit.ridge.cv <- cv.glmnet(X.train, train$y, alpha=0, family="binomial", nfolds = K, grouped = FALSE, type.measure = "class", parallel = T)
plot(fit.ridge.cv)
```

Perchè abbiamo usato cv.glmnet??? Perchè vogliamo mostrare come la crossvalidation sia nel nostro caso piuttosto inutile, avendo un dataset molto grande i risultati sulle varie folds sono estremamente stabili/simili. Così abbiamo giustificato l'utilizzo del metodo holdout invece della cross-validation.

```{r}
X.test <- model.matrix(y~., test)[,-1]

yhat.ridge = predict(fit.ridge.cv, X.test, s = "lambda.1se",  type="response")

MyConfusionMatrix(test$y, yhat.ridge, threshold = 0.5, title = "Ridge Logit")
cat("Accuracy = ", 1-misClassError(test$y, yhat.ridge, threshold = 0.5))
```


```{r}
InformationValue::plotROC(test$y, yhat.ridge)
```

Commento.
Grafico confronto coefficienti.

Possiamo verificare ulteriormente quanto detto circa la cross-validation.

```{r eval=FALSE, include=FALSE}
K <- 10
folds <- sample(rep(1:K, length=nrow(train)))

accs <- c()
precs <- c()

for(k in 1:K){
  fit <- glm(y ~ ., train[which(folds!=k),], family="binomial")
  x.out=train[which(folds==k),] %>% select(-y) ### lascio fuori la "cartella" k-esima per la fase di training
  yhat.cv=predict(fit, x.out, type="response") ### predico sulla "cartella" k-esima
  y.out=train$y[which(folds==k)]
  accs[k] <- 1-misClassError(y.out, yhat.cv, threshold = 0.5)
  precs[k] <- precision(y.out, yhat.cv, threshold = 0.5)
  print(k)
}

boxplot(accs,ylim=c(0,1))
boxplot(precs,ylim=c(0,1))
```

### Lasso

```{r}
K <- 10
fit.lasso.cv <- cv.glmnet(X.train, train$y, alpha=1, family="binomial", nfolds = K, grouped = FALSE, type.measure = "class", parallel = T)
plot(fit.lasso.cv)
```

```{r}
cat(paste(c("Variables excluded by lasso selection are:", rownames(coef(fit.lasso.cv, s = "lambda.1se"))[(coef(fit.lasso.cv, s = "lambda.1se") == 0)[,1]]), collapse=" \n" ))
```

```{r}
yhat.lasso <-  predict(fit.lasso.cv, X.test, s = "lambda.1se",  type="response")

MyConfusionMatrix(test$y, yhat.lasso, threshold = 0.5, title="Lasso Logit")
cat("Accuracy = ", 1-misClassError(test$y, yhat.lasso, threshold = 0.5))
```

```{r}
InformationValue::plotROC(test$y, yhat.lasso)
```

La lasso e' bella!

## Random Forest

```{r}
customTuneRF<- function (data, ntree, mtryStart){
  data <- data %>% group_by(y) %>% slice_sample(n=1e5) %>% ungroup() 
  x <- data %>% select(-y)
  y <- data$y
  tuning_data <- data %>% group_by(y) %>% slice_sample(n=5e4) %>% ungroup()
  tuning_x <- tuning_data %>% select(-y)
  tuning_y <- tuning_data$y
  tune <- tuneRF(tuning_x, tuning_y, trace=T, strata=tuning_y, mtryStart=mtryStart, ntreeTry = 50)
  print("Tuning is over!")
  randomForest(x, y, mtry=tune[which.min(tune[, 
      2]), 1], ntree=ntree, strata=y, importance=T, do.trace=T)
}
```

```{r}
fit.rf.150t = customTuneRF(train, ntree=200, mtryStart=7)
```

```{r}
fit.rf.150t$err.rate %>%
  as.data.frame() %>%
  cbind(ntrees=seq(1,nrow(fit.rf.150t$err.rate))) %>%
  rename("Default" = "0", "FullyPaid" = "1", "Overall" = "OOB") %>%
  gather(Error, Value, -ntrees) %>%
  ggplot() +
  geom_line(aes(x=ntrees,y= Value, col=Error)) +
  scale_y_continuous(labels = scales::percent) +
  scale_color_manual(values = c("darkred", "darkgreen", "black")) + 
  labs(x = "# Trees", y = "OOB Error", title = "Random Forest Progression") + 
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 16))
```

```{r}
fit.rf.150t$importance %>%
  cbind("Variable"=rownames(fit.rf.150t$importance)) %>%
  as.data.frame() %>%
  mutate(MeanDecreaseAccuracy = as.numeric(as.character(MeanDecreaseAccuracy))) %>%
  ggplot() +
  geom_point(aes(x=MeanDecreaseAccuracy, y = reorder(Variable, MeanDecreaseAccuracy), col = MeanDecreaseAccuracy > 0)) +
  scale_color_manual(values=c("red", "black"), guide="none") +
  scale_x_continuous(labels=scales::percent) +
  labs(x= "Mean Decrease Accuracy", y = "", title = "Variables Importance in Random Forest", subtitle = paste("Overall Training Accuracy =", 1-misClassError(fit.rf.150t$y, as.numeric(as.character(fit.rf.150t$predicted)),0.5) )) + 
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, size = 16),
        plot.subtitle = element_text(hjust=0.5,size=12))
```

application_type e tax_liens aumentano l'accuracy quando non sono presenti negli alberi, tuttavia la differenza è minima, per cui non vale la pena girare un nuovo modello escludendole.

```{r}
yhat.rf = predict(fit.rf.150t, test %>% select(-y), type="prob", norm.votes=T)

MyConfusionMatrix(test$y, yhat.rf[,2], threshold = 0.5)

cat("Accuracy = ", 1-misClassError(test$y, yhat.rf[,2], threshold = 0.5))
```

```{r}
InformationValue::plotROC(test$y, yhat.rf[,2])
```

## Survival Analysis

In order to perform survival analysis we define three possible outcomes for a lending: "Fully Paid", "Default" and "Pre-Paid", whose meanings are pretty clear.

To distinguish between Regalur Payment and Early Payment we define a tolerance of -1 month since our dates are all represented as month-year.

```{r}
prep_surv <- function(d, plots=T){
  d <- d %>% 
    as.data.frame() %>%
    mutate(actual_duration_to_term = as.numeric(last_pymnt_d - issue_d) / (as.numeric(substring(as.character(term),0,2))*(365/12)))
  if (plots){
    ht <- ggplot(d) + 
      geom_histogram(aes(x=actual_duration_to_term, y = ..count../sum(nrow(d)), fill=y), bins=50) +
      scale_fill_manual(labels=c("Default", "Fully Paid"), values=c("darkred","darkgreen")) + 
      scale_x_continuous(labels = scales::percent) + 
      scale_y_continuous(labels = scales::percent) + 
      labs(x="Time to end of lending", y = "Percentage of lendings", title="Time to end of lending by outcome") + 
      guides(fill=guide_legend(title="Outcome"))+
      theme_minimal() + 
      theme(plot.title = element_text(hjust = 0.5, size = 16),
          plot.subtitle = element_text(hjust = 0.5, size = 12))
    d_pie <- d %>%
      mutate(y = as.factor(case_when(
        y == 0 ~ 1, ### Default
        (y == 1) & (actual_duration_to_term < 0.8) ~ -1, ### Early Payment
        T ~ 0 ### Regular Payment
      )))
    pie <- piechart(d_pie, "y") +
      scale_fill_manual(labels=c("Regular Payment", "Early Payment", "Default"), values=c("darkgreen",  "darkgray", "darkred"))
  }
  d <- d %>%
    mutate(actual_duration_to_term = ifelse(y==0, actual_duration_to_term, 1)) %>%
    mutate(actual_duration_to_term = ifelse(actual_duration_to_term > 1, 1, actual_duration_to_term)) %>%
      # ignoro gli early payment e i pagamenti in ritardo, settando il tempo a 1 per loro, intendendo che           # questi prestiti sono sopravvissuti fino alla fine.
    mutate(status = ifelse(y==0,1,0)) # status is the opposite of y: status 0 means Fully Paid, status 1 means Default (Failure in Survival Analysis lexicon).
  if (plots) return(list(ht=ht,pie=pie))
  else return(d)
}

set.seed(1000)
train_surv <- sample_frac(acc, 0.7)
test_surv <- anti_join(acc, train_surv)
set.seed(1000)
train_surv <- prep_surv(train_surv, plots=F)
test_surv <- prep_surv(test_surv, plots=F)

ret <- prep_surv(acc, plots=T)
ret$ht
ret$pie
```

```{r}
### Check if everything is as intended

 ggplot(train_surv) + 
      geom_histogram(aes(x=actual_duration_to_term, y = ..count../sum(nrow(train_surv)), fill=as.character(status)), bins=25) +
      scale_fill_manual(labels=c("Fully Paid", "Default"), values=c("darkgreen","darkred")) + 
      scale_x_continuous(labels = scales::percent) + 
      scale_y_continuous(labels = scales::percent) + 
      labs(x="Time to end of lending", y = "Percentage of lendings", title="Time to end of lending by outcome") + 
      guides(fill=guide_legend(title="Outcome"))+
      theme_minimal() + 
      theme(plot.title = element_text(hjust = 0.5, size = 16),
          plot.subtitle = element_text(hjust = 0.5, size = 12))
```

### Survival function

```{r}
fit <- survfit(Surv(actual_duration_to_term, status) ~ 1, data = train_surv)
ggsurvplot(fit, xlab = "Years", legend= "none", ggtheme = theme_minimal())
summary(fit, times = 0.5)
```

### Cox

```{r}
train_surv <- train_surv %>% select(all_of(model_variables), actual_duration_to_term, status) %>% select(-y)
test_surv <- test_surv %>% select(all_of(model_variables), actual_duration_to_term, status) %>% select(-y)
surv_scaling <- preProcess(train_surv %>% select(-status, -actual_duration_to_term), method = c("center", "scale"))
train_surv <- predict(surv_scaling, train_surv)
test_surv <- predict(surv_scaling, test_surv)

train_surv <- train_surv %>% group_by(status) %>% slice_sample(n=min(table(train$y))) %>% ungroup()
```

```{r}
fit <- survfit(Surv(actual_duration_to_term, status) ~ 1, data = train_surv)
ggsurvplot(fit, xlab = "Years", legend= "none", ggtheme = theme_minimal())
summary(fit, times = 0.5)
```
#### Valutare assunzione «Proportional Hazards»

Per valutare l'assunzione di Proportional Hazards per le covariate si procede dapprima con un check visuale della log(-log(Survival)), che valuta l'assunzione di PH per ogni covariata indipendentemente dalle altre, e successivamente ci si serve dei residui Schoenfeld per valutare l'assunzione di PH tenendo conto anche dalle altre covariate (modello multivariato).

1. log[-log(SKM (t))] --- Graphical check

2. Schoenfeld residuals --- Graphical check

##### 1. log[-log(SKM (t))] --- Graphical check

Per l'assunzione di PH abbiamo: $S_X(t) = S_0(t) e^{(\beta' X)}$
che può essere riscritta come: $log(-log(S_X(t))) - log(-log(S_0(t))) = \beta' X$
ne segue che la differenza tra i due logaritmi è costante rispetto al tempo se è valida l'assunzione di PH. 

Questo tipo di verifica può essere fatto unicamente sulle variabili non continue, poiché il $log(-log(S_0(t)))$ deve essere confrontato con $log(-log(S_X(t)))$ per ciascun valore di X su tutto l'intervallo temporale.

```{r}
par(mfrow=c(2,2),mar=c(4,4,2,2))

km.addr_state <- survfit(Surv(actual_duration_to_term, status) ~ addr_state, data=train_surv)
plot(km.addr_state, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of address state")

km.appl_type <- survfit(Surv(actual_duration_to_term, status) ~ application_type, data=train_surv)
plot(km.appl_type, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of application type")

km.emp_length <- survfit(Surv(actual_duration_to_term, status) ~ emp_length, data=train_surv)
plot(km.emp_length, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of employment length")

km.home_ownership <- survfit(Surv(actual_duration_to_term, status) ~ home_ownership, data=train_surv)
plot(km.addr_state, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of home ownership")

km.init_list <- survfit(Surv(actual_duration_to_term, status) ~ initial_list_status, data=train_surv)
plot(km.init_list, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of initial list status")

km.purpose <- survfit(Surv(actual_duration_to_term, status) ~ purpose, data=train_surv)
plot(km.purpose, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of purpose")

km.term <- survfit(Surv(actual_duration_to_term, status) ~ term, data=train_surv)
plot(km.term, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of term")

km.ver_status <- survfit(Surv(actual_duration_to_term, status) ~ verification_status, data=train_surv)
plot(km.ver_status,fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of verification status")

km.fico_class <- survfit(Surv(actual_duration_to_term, status) ~ fico_class, data=train_surv)
plot(km.fico_class, fun="cloglog", ylab="log(-log(Survival))", xlab="log(time_to_term)", main="Check PH assumption of fico class")
```

L'assunzione di PH pare valere per tutte le variabili categoriche, mentre sembra che non valga per la "fico class".

##### 2. Schoenfeld residuals --- Graphical check

I residui Schoenfeld sono definiti come: $r_j = x_j - E[x_j|R_j]$ \
dove $x_j$ è la covariata dell'individuo che *fallisce* al tempo $t_{(j)}$ e $R_j$ è il risk set al tempo $t_{(j)}$.
Ci si aspetta che il valore atteso dei residui sia 0, ne segue che l'andamento dei residui rispetto al tempo deve essere costante. Si plottano i residui Schoenfeld standardizzati.


```{r}
model.cox.base <- coxph(Surv(actual_duration_to_term, status) ~ ., data = train_surv)
czph <- cox.zph(model.cox.base, terms = F)

par(mfrow=c(3,3),mar=c(4,4,2,2))
plot(czph, resid=FALSE)
```

Per molte variabili non vale l'assunzione di PH, le escludiamo. Alcune, sebbene graficamente sarebbero da escludere, sono invece tenute per via della scala.

###
Ad esempio beta(t) di annual_inc è chiaramente non costante, tuttavia la variazione avviene su un ordine di grandezza di 1e-6 !!! 
###

```{r}
train_ph <- train_surv %>% select(-application_type, -initial_list_status, -int_rate, -num_rev_tl_bal_gt_0, -pct_tl_nvr_dlq, -purpose, -revol_bal, -revol_util, -term, -total_acc, -verification_status, -mo_sin_earliest_cr_line, -num_bc_not_sats, -home_ownership, -addr_state)
```

```{r}
model.cox.ph <- coxph(Surv(actual_duration_to_term, status) ~ ., train_ph, x=T,y=T)
formula.cox.ph <- paste(names(model.cox.ph$coefficient), collapse = "+")
  
model.cox.strata <- coxph(
  Surv(actual_duration_to_term, status) ~
    dti +
    delinq_2yrs +
    emp_length +
    loan_amnt +
    mo_sin_old_il_acct +
    mort_acc+num_bc_tl +
    num_op_rev_tl +
    open_acc +
    percent_bc_gt_75 +
    pub_rec +
    tax_liens +
    fico_class +
    num_not_sats + 
    survival::strata(application_type) +
    survival::strata(initial_list_status) +
    survival::strata(purpose) +
    survival::strata(term) +
    survival::strata(verification_status) +
    survival::strata(home_ownership) +
    survival::strata(addr_state),
  train_surv, x =T, y=T) 
summary(model.cox.strata)
```


### Functional form of contiuous variables

```{r}
mar.res<-resid(model.cox.base,type='martingale')

for (variable in model_num_variables){
  ms <- coxph(Surv(actual_duration_to_term, status>0) ~ ns(eval(as.name(variable)),knots=c(-1,0,1)), data = train_surv) # ns natural cubic splines, e knots sono i nodi delle splines.
  pred <- predict(ms, type="terms", se=TRUE) # terms indica che voglio beta * x
  hfit <- pred$fit[,1]
  hse <- pred$se[,1]
  hmat <- cbind(hfit, hfit+1.96*hse,hfit-1.96*hse)
  o <- order(train_surv[[variable]])
  matplot(train_surv[[variable]][o], hmat[o, ], pch="*",col=c("red","orangered","orangered"), lwd=c(2,1,1),xlab = variable, ylab="log hazard ratio",main=paste("Check functional form of",variable),type="l")
  
  ms <- coxph(Surv(actual_duration_to_term, status) ~ eval(as.name(variable)), data = train_surv) # ns natural cubic splines, e knots sono i nodi delle splines.
  pred <- predict(ms, type="terms", se=TRUE) # terms indica che voglio beta * x
  hfit <- pred$fit[,1]
  hse <- pred$se[,1]
  hmat <- cbind(hfit, hfit+1.96*hse,hfit-1.96*hse)
  o <- order(train_surv[[variable]])
  matplot(train_surv[[variable]][o], hmat[o, ], pch="*",col=c("blue","cornflowerblue","cornflowerblue"), lwd=c(2,1,1),type="l", add=T)
  legend("topright",c("natural spline","linear"),col=c(2,4),lwd=2,bty="n")
}
```

### Calibration

Si procede con la costruzione dei modelli, specificando l'opzione x = TRUE per poter poi utilizzare la funzione Score del pacchetto riskRegression.
Creo un modello aumentato con le variabili per cui non vale PH.


```{r}
score <- Score(list("PH model"=model.cox.ph,"Stratified Model"=model.cox.strata),
              formula=Surv(actual_duration_to_term, status)~1,
              data=train_surv, conf.int=F,
              times=seq(0.1,0.9,0.2),
              plots=c("calibration","ROC"),
              progress.bar=1)
```

Si decide di prendere il time-point a metà del termine e si valutano le performance dei modelli sui tre aspetti: calibrazione, discriminazione, net benefit.

Per valutare la calibrazione dei modelli si usano insieme il Calibration Plot e il Brier Score.

```{r}
plotCalibration(score,times=0.5, cens.method="local",method="quantile", q=20, auc.in.legend = F)
title(main="Calibration at half term")
```

### Discrimination

```{r}
plotROC(score,times=0.1,cens.method="local")
plotROC(score,times=0.5,cens.method="local")
plotROC(score,times=0.9,cens.method="local")

title(main="time-dependent ROC at half term")
```




### Predictions

```{r}
fit.cox.strata<-survfit(model.cox.strata,newdata=test_surv)
yhat.cox.strata <- as.numeric(summary(fit.cox.strata,times=1)$surv)

InformationValue::misClassError((1-test_surv$status), yhat.cox.strata)

MyConfusionMatrix(as.factor(as.character(1-test_surv$status)), yhat.cox.strata, threshold = 0.5)
```


# Conclusions


```{r}
score <- Score(list("LogReg"=fit.glm,
                    "LogReg PCA"=fit.pca,
                    "LogRidge"=fit.ridge.cv,
                    "LogRegLasso"=fit.lasso.cv,
                    "RandFor"=fit.rf.150t),
              formula=y~1,
              data=test, conf.int=F,
              plots=c("calibration","ROC"),
              progress.bar=1)

score <- Score(list("LogReg"=fit.glm),
              formula=y~1,
              data=test, conf.int=F,
              plots=c("calibration","ROC"),
              progress.bar=1)

plotCalibration(score,times=0.5, cens.method="local",method="quantile", q=20, auc.in.legend = F)
title(main="Calibration at half term")
```

```{r fig.height=6, fig.width=10}
plot_precision_vs_npred(test$y, list("glm"=yhat.glm.under, "pca"=yhat.pca, "backward"=yhat.glm.backward, "ridge"=yhat.ridge, "lasso"=yhat.lasso,"RandomForest"=yhat.rf[,2], "Cox"=yhat.cox), title = "Results")
```

```{r fig.width=10, fig.height=6}
plot_precision_at_k(test$y, list("under"=yhat.glm.under, "unbal"=yhat.glm.unbalanced, "weighted"=yhat.glm.weighted))
```

```{r}
stopCluster(cl)
```

